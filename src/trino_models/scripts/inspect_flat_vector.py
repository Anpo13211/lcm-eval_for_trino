"""
Trino Flat-Vector Model Inspector

ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ã®Flat-Vectorãƒ¢ãƒ‡ãƒ«ã®è©³ç´°æƒ…å ±ã‚’è¡¨ç¤ºã€‚
ã“ã‚Œã¯ã€æ—¢å­˜ã®PostgreSQLç”¨Flat-Vectorãƒ¢ãƒ‡ãƒ«ã‚’trinoå‘ã‘ã«å†å®Ÿè£…ã—ãŸã‚‚ã®ã§ã™ã€‚

Usage:
    # ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰å®Ÿè¡Œ
    python -m trino_models.scripts.inspect_flat_vector \
        --model_dir models/trino_flat_vector --seed 42
"""

import sys
import os
from pathlib import Path
import argparse
import json

# ç’°å¢ƒå¤‰æ•°ã®è¨­å®šï¼ˆå¿…é ˆ - importå‰ã«å®Ÿè¡Œï¼‰
for i in range(11):
    env_key = f'NODE{i:02d}'
    env_value = os.environ.get(env_key)
    if env_value in (None, '', 'None'):
        os.environ[env_key] = '[]'

# ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒsrc/trino_models/scripts/ã«ã‚ã‚‹å ´åˆã€src/ã‚’è¦ªãƒ‘ã‚¹ã«è¿½åŠ 
script_dir = Path(__file__).resolve().parent
src_dir = script_dir.parent.parent
if str(src_dir) not in sys.path:
    sys.path.insert(0, str(src_dir))

import lightgbm as lgb


def inspect_model(model_dir: Path, seed: int):
    """
    ãƒ¢ãƒ‡ãƒ«ã®è©³ç´°æƒ…å ±ã‚’è¡¨ç¤º
    
    Args:
        model_dir: ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        seed: ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰
    """
    print("=" * 80)
    print("Trino Flat-Vector Model Inspector")
    print("ï¼ˆPostgreSQLç”¨Flat-Vectorãƒ¢ãƒ‡ãƒ«ã®trinoå‘ã‘å†å®Ÿè£…ï¼‰")
    print("=" * 80)
    print(f"Model directory: {model_dir}")
    print(f"Seed: {seed}")
    print()
    
    # 1. æ¼”ç®—å­ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¾æ›¸ã®èª­ã¿è¾¼ã¿
    print("ğŸ“Š æ¼”ç®—å­ã‚¿ã‚¤ãƒ—æƒ…å ±")
    print("-" * 80)
    
    op_idx_path = model_dir / f'op_idx_dict_{seed}.json'
    if not op_idx_path.exists():
        print(f"âŒ æ¼”ç®—å­ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¾æ›¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {op_idx_path}")
        return
    
    with open(op_idx_path, 'r') as f:
        op_idx_dict = json.load(f)
    
    print(f"æ¼”ç®—å­ã‚¿ã‚¤ãƒ—æ•°: {len(op_idx_dict)}")
    print("\næ¼”ç®—å­ã‚¿ã‚¤ãƒ—ä¸€è¦§:")
    for op_name, idx in sorted(op_idx_dict.items(), key=lambda x: x[1]):
        print(f"  {idx:3d}: {op_name}")
    print()
    
    # 2. ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
    print("ğŸ¤– ãƒ¢ãƒ‡ãƒ«æƒ…å ±")
    print("-" * 80)
    
    model_path = model_dir / f'flat_vector_model_{seed}.txt'
    if not model_path.exists():
        print(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {model_path}")
        return
    
    bst = lgb.Booster(model_file=str(model_path))
    
    print(f"ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«: {model_path}")
    print(f"ãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•°: {bst.current_iteration()}")
    print(f"ãƒ™ã‚¹ãƒˆã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³: {bst.best_iteration}")
    print(f"ç‰¹å¾´é‡æ•°: {bst.num_feature()}")
    print()
    
    # ç‰¹å¾´é‡é‡è¦åº¦
    feature_importance = bst.feature_importance(importance_type='gain')
    feature_names = [f"feature_{i}" for i in range(len(feature_importance))]
    
    # ç‰¹å¾´é‡åã‚’æ¨æ¸¬ï¼ˆå‰åŠã¯å‡ºç¾å›æ•°ã€å¾ŒåŠã¯ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£ï¼‰
    feature_type_names = []
    for i in range(len(feature_importance)):
        if i < len(op_idx_dict):
            # æ¼”ç®—å­ã®å‡ºç¾å›æ•°ç‰¹å¾´
            op_name = [name for name, idx in op_idx_dict.items() if idx == i][0]
            feature_type_names.append(f"Count_{op_name}")
        else:
            # æ¼”ç®—å­ã®ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£ç‰¹å¾´
            op_idx = i - len(op_idx_dict)
            op_name = [name for name, idx in op_idx_dict.items() if idx == op_idx][0]
            feature_type_names.append(f"Card_{op_name}")
    
    # é‡è¦åº¦ã§ã‚½ãƒ¼ãƒˆ
    feature_importance_sorted = sorted(
        zip(feature_type_names, feature_importance),
        key=lambda x: x[1],
        reverse=True
    )
    
    print("ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆTop 10ï¼‰:")
    for i, (feat_name, importance) in enumerate(feature_importance_sorted[:10], 1):
        print(f"  {i:2d}. {feat_name:30s}: {importance:10.2f}")
    print()
    
    # 3. ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®èª­ã¿è¾¼ã¿
    print("ğŸ“Š ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¡ãƒˆãƒªã‚¯ã‚¹")
    print("-" * 80)
    
    metrics_path = model_dir / f'metrics_{seed}.json'
    if not metrics_path.exists():
        print(f"âš ï¸  ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {metrics_path}")
        return
    
    with open(metrics_path, 'r') as f:
        metrics_data = json.load(f)
    
    # ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    print("ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:")
    for key, value in metrics_data.get('hyperparameters', {}).items():
        print(f"  - {key}: {value}")
    print()
    
    # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°/æ¤œè¨¼/ãƒ†ã‚¹ãƒˆãƒ¡ãƒˆãƒªã‚¯ã‚¹
    for dataset_name in ['train', 'validation', 'test']:
        if dataset_name not in metrics_data:
            continue
        
        metrics = metrics_data[dataset_name]
        print(f"ã€{dataset_name.capitalize()}ã‚»ãƒƒãƒˆã€‘")
        print(f"  - ã‚µãƒ³ãƒ—ãƒ«æ•°: {metrics['num_samples']}")
        print(f"  - RMSE: {metrics['rmse']:.4f}ç§’ ({metrics['rmse']*1000:.2f}ms)")
        print(f"  - MAPE: {metrics['mape']:.4f}")
        print(f"  - Median Q-Error: {metrics['median_q_error']:.4f}")
        print(f"  - P95 Q-Error: {metrics['p95_q_error']:.4f}")
        print(f"  - P99 Q-Error: {metrics.get('p99_q_error', 0.0):.4f}")
        print(f"  - Max Q-Error: {metrics['max_q_error']:.4f}")
        print()
    
    print("=" * 80)


def main():
    parser = argparse.ArgumentParser(
        description='Inspect Trino Flat-Vector Model (Trinoå‘ã‘å†å®Ÿè£…ç‰ˆ)'
    )
    
    parser.add_argument('--model_dir', type=str, required=True,
                        help='ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    parser.add_argument('--seed', type=int, default=42,
                        help='ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 42ï¼‰')
    
    args = parser.parse_args()
    
    model_dir = Path(args.model_dir)
    
    if not model_dir.exists():
        print(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {model_dir}")
        return
    
    inspect_model(model_dir, args.seed)


if __name__ == "__main__":
    main()

