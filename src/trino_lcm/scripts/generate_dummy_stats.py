#!/usr/bin/env python3
"""
ãƒ€ãƒŸãƒ¼çµ±è¨ˆæƒ…å ±ã‚’ç”Ÿæˆã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
Trinoãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ããªã„å ´åˆã®é–‹ç™ºãƒ»ãƒ†ã‚¹ãƒˆç”¨

Usage:
    # å˜ä¸€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
    python src/trino_lcm/scripts/generate_dummy_stats.py \
        --template iceberg_imdb \
        --output iceberg_accidents \
        --tables accidents,severity,conditions
    
    # ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
    python src/trino_lcm/scripts/generate_dummy_stats.py \
        --template iceberg_imdb \
        --generate-all
"""

import argparse
import json
import sys
from pathlib import Path
from typing import Dict, List, Any, Tuple


DATASETS = [
    'accidents', 'airline', 'baseball', 'basketball',
    'carcinogenesis', 'consumer', 'credit', 'employee',
    'fhnk', 'financial', 'geneea', 'genome', 'hepatitis',
    'imdb', 'movielens', 'seznam', 'ssb', 'tournament',
    'tpc_h', 'walmart'
]


def load_template(template_dir: Path) -> Tuple[Dict, Dict, Dict]:
    """
    ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆçµ±è¨ˆæƒ…å ±ã‚’èª­ã¿è¾¼ã‚€
    
    Returns:
        tuple: (table_stats, column_stats, metadata)
    """
    table_stats_file = template_dir / 'table_stats.json'
    column_stats_file = template_dir / 'column_stats.json'
    metadata_file = template_dir / 'metadata.json'
    
    if not table_stats_file.exists():
        raise FileNotFoundError(f"ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {table_stats_file}")
    
    with open(table_stats_file, 'r', encoding='utf-8') as f:
        table_stats = json.load(f)
    
    with open(column_stats_file, 'r', encoding='utf-8') as f:
        column_stats = json.load(f)
    
    with open(metadata_file, 'r', encoding='utf-8') as f:
        metadata = json.load(f)
    
    return table_stats, column_stats, metadata


def generate_dummy_table_stats(table_names: List[str], template: Dict) -> Dict:
    """
    ãƒ€ãƒŸãƒ¼ã®ãƒ†ãƒ¼ãƒ–ãƒ«çµ±è¨ˆã‚’ç”Ÿæˆ
    
    Args:
        table_names: ãƒ†ãƒ¼ãƒ–ãƒ«åã®ãƒªã‚¹ãƒˆ
        template: ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆçµ±è¨ˆæƒ…å ±
    
    Returns:
        Dict: ãƒ€ãƒŸãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«çµ±è¨ˆ
    """
    dummy_stats = {}
    
    # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‹ã‚‰1ã¤ã®ãƒ†ãƒ¼ãƒ–ãƒ«çµ±è¨ˆã‚’å–å¾—
    if template:
        template_table = next(iter(template.values()))
    else:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        template_table = {
            'reltuples': 10000.0,
            'relpages': 100,
            'table_name': 'template',
            'row_count': 10000.0,
            'num_columns': 5
        }
    
    for table_name in table_names:
        dummy_stats[table_name] = {
            'reltuples': template_table.get('reltuples', 10000.0),
            'relpages': template_table.get('relpages', 100),
            'table_name': table_name,
            'row_count': template_table.get('row_count', 10000.0),
            'num_columns': template_table.get('num_columns', 5)
        }
    
    return dummy_stats


def generate_dummy_column_stats(
    table_names: List[str],
    columns_per_table: int,
    template: Dict
) -> Dict:
    """
    ãƒ€ãƒŸãƒ¼ã®ã‚«ãƒ©ãƒ çµ±è¨ˆã‚’ç”Ÿæˆ
    
    Args:
        table_names: ãƒ†ãƒ¼ãƒ–ãƒ«åã®ãƒªã‚¹ãƒˆ
        columns_per_table: ãƒ†ãƒ¼ãƒ–ãƒ«ã‚ãŸã‚Šã®ã‚«ãƒ©ãƒ æ•°
        template: ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆçµ±è¨ˆæƒ…å ±
    
    Returns:
        Dict: ãƒ€ãƒŸãƒ¼ã‚«ãƒ©ãƒ çµ±è¨ˆ
    """
    dummy_stats = {}
    
    # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‹ã‚‰1ã¤ã®ã‚«ãƒ©ãƒ çµ±è¨ˆã‚’å–å¾—
    if template:
        template_column = next(iter(template.values()))
    else:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        template_column = {
            'n_distinct': 100,
            'null_frac': 0.0,
            'avg_width': 10,
            'correlation': 0.0,
            'data_type': 'integer'
        }
    
    for table_name in table_names:
        for col_idx in range(columns_per_table):
            col_name = f"col_{col_idx}"
            key = f"('{table_name}', '{col_name}')"
            
            dummy_stats[key] = {
                'n_distinct': template_column.get('n_distinct', 100),
                'null_frac': template_column.get('null_frac', 0.0),
                'avg_width': template_column.get('avg_width', 10),
                'correlation': template_column.get('correlation', 0.0),
                'data_type': template_column.get('data_type', 'integer'),
                'table': table_name,
                'column': col_name
            }
    
    return dummy_stats


def generate_from_template(
    template_dir: Path,
    output_dir: Path,
    dataset_name: str,
    table_names: List[str] = None
):
    """
    ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‹ã‚‰ãƒ€ãƒŸãƒ¼çµ±è¨ˆæƒ…å ±ã‚’ç”Ÿæˆ
    
    Args:
        template_dir: ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        dataset_name: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå
        table_names: ãƒ†ãƒ¼ãƒ–ãƒ«åãƒªã‚¹ãƒˆï¼ˆçœç•¥æ™‚ã¯ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã¨åŒã˜æ§‹é€ ï¼‰
    """
    print(f"ğŸ“‹ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆèª­ã¿è¾¼ã¿ä¸­: {template_dir}")
    
    try:
        template_table_stats, template_column_stats, template_metadata = load_template(template_dir)
    except Exception as e:
        print(f"âŒ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}", file=sys.stderr)
        return False
    
    # ãƒ†ãƒ¼ãƒ–ãƒ«åãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã€ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã¨åŒã˜æ•°ã®ãƒ€ãƒŸãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ç”Ÿæˆ
    if not table_names:
        num_tables = len(template_table_stats)
        table_names = [f"table_{i}" for i in range(num_tables)]
    
    print(f"ğŸ“Š ãƒ€ãƒŸãƒ¼çµ±è¨ˆæƒ…å ±ã‚’ç”Ÿæˆä¸­...")
    print(f"   ãƒ†ãƒ¼ãƒ–ãƒ«æ•°: {len(table_names)}")
    print(f"   ãƒ†ãƒ¼ãƒ–ãƒ«å: {', '.join(table_names)}")
    
    # ãƒ€ãƒŸãƒ¼çµ±è¨ˆã‚’ç”Ÿæˆ
    dummy_table_stats = generate_dummy_table_stats(table_names, template_table_stats)
    
    # ã‚«ãƒ©ãƒ æ•°ã‚’ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‹ã‚‰æ¨å®š
    avg_columns = (
        sum(t.get('num_columns', 5) for t in template_table_stats.values()) 
        / len(template_table_stats)
        if template_table_stats else 5
    )
    
    dummy_column_stats = generate_dummy_column_stats(
        table_names,
        int(avg_columns),
        template_column_stats
    )
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°
    dummy_metadata = {
        'catalog': 'iceberg',
        'schema': dataset_name,
        'num_tables': len(dummy_table_stats),
        'num_columns': len(dummy_column_stats),
        'is_dummy': True,
        'template': str(template_dir)
    }
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    table_stats_file = output_dir / 'table_stats.json'
    column_stats_file = output_dir / 'column_stats.json'
    metadata_file = output_dir / 'metadata.json'
    
    with open(table_stats_file, 'w', encoding='utf-8') as f:
        json.dump(dummy_table_stats, f, indent=2, ensure_ascii=False)
    
    with open(column_stats_file, 'w', encoding='utf-8') as f:
        json.dump(dummy_column_stats, f, indent=2, ensure_ascii=False)
    
    with open(metadata_file, 'w', encoding='utf-8') as f:
        json.dump(dummy_metadata, f, indent=2, ensure_ascii=False)
    
    print(f"\nâœ… ãƒ€ãƒŸãƒ¼çµ±è¨ˆæƒ…å ±ã‚’ä¿å­˜ã—ã¾ã—ãŸ:")
    print(f"   ğŸ“„ {table_stats_file}")
    print(f"   ğŸ“„ {column_stats_file}")
    print(f"   ğŸ“„ {metadata_file}")
    print()
    print(f"âš ï¸  æ³¨æ„: ã“ã‚Œã¯ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã§ã™")
    print(f"   å®Ÿéš›ã®çµ±è¨ˆæƒ…å ±ã¨ã¯ç•°ãªã‚‹ãŸã‚ã€ãƒ¢ãƒ‡ãƒ«ã®ç²¾åº¦ã¯ä¿è¨¼ã•ã‚Œã¾ã›ã‚“")
    print(f"   é–‹ç™ºãƒ»ãƒ†ã‚¹ãƒˆç›®çš„ã§ã®ã¿ä½¿ç”¨ã—ã¦ãã ã•ã„")
    
    return True


def main():
    parser = argparse.ArgumentParser(
        description='ãƒ€ãƒŸãƒ¼çµ±è¨ˆæƒ…å ±ã‚’ç”Ÿæˆ'
    )
    parser.add_argument(
        '--template',
        default='iceberg_imdb',
        help='ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: iceberg_imdbï¼‰'
    )
    parser.add_argument(
        '--output',
        help='å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåï¼ˆä¾‹: iceberg_accidentsï¼‰'
    )
    parser.add_argument(
        '--tables',
        help='ãƒ†ãƒ¼ãƒ–ãƒ«åã®ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šãƒªã‚¹ãƒˆï¼ˆçœç•¥æ™‚ã¯è‡ªå‹•ç”Ÿæˆï¼‰'
    )
    parser.add_argument(
        '--generate-all',
        action='store_true',
        help='ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ€ãƒŸãƒ¼çµ±è¨ˆã‚’ç”Ÿæˆ'
    )
    parser.add_argument(
        '--base-dir',
        default='datasets_statistics',
        help='çµ±è¨ˆæƒ…å ±ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: datasets_statisticsï¼‰'
    )
    
    args = parser.parse_args()
    
    base_dir = Path(args.base_dir)
    template_dir = base_dir / args.template
    
    if not template_dir.exists():
        print(f"âŒ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {template_dir}", file=sys.stderr)
        sys.exit(1)
    
    # ãƒ†ãƒ¼ãƒ–ãƒ«åãƒªã‚¹ãƒˆ
    table_names = [t.strip() for t in args.tables.split(',')] if args.tables else None
    
    if args.generate_all:
        # ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å¯¾ã—ã¦ãƒ€ãƒŸãƒ¼çµ±è¨ˆã‚’ç”Ÿæˆ
        print(f"ğŸš€ ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ€ãƒŸãƒ¼çµ±è¨ˆã‚’ç”Ÿæˆä¸­...")
        print(f"   ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ: {template_dir}")
        print(f"   ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ•°: {len(DATASETS)}")
        print()
        
        success_count = 0
        for dataset in DATASETS:
            output_dir = base_dir / f"iceberg_{dataset}"
            
            # æ—¢ã«å­˜åœ¨ã™ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            if output_dir.exists() and (output_dir / 'metadata.json').exists():
                print(f"â­ï¸  {dataset}: æ—¢ã«å­˜åœ¨ã—ã¾ã™ã€ã‚¹ã‚­ãƒƒãƒ—")
                continue
            
            print(f"ğŸ“Š {dataset} ã®ãƒ€ãƒŸãƒ¼çµ±è¨ˆã‚’ç”Ÿæˆä¸­...")
            
            if generate_from_template(
                template_dir=template_dir,
                output_dir=output_dir,
                dataset_name=dataset,
                table_names=table_names
            ):
                success_count += 1
        
        print(f"\nâœ… {success_count}/{len(DATASETS)} ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ€ãƒŸãƒ¼çµ±è¨ˆã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
        
    elif args.output:
        # å˜ä¸€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ€ãƒŸãƒ¼çµ±è¨ˆã‚’ç”Ÿæˆ
        output_dir = base_dir / args.output
        dataset_name = args.output.replace('iceberg_', '')
        
        generate_from_template(
            template_dir=template_dir,
            output_dir=output_dir,
            dataset_name=dataset_name,
            table_names=table_names
        )
    
    else:
        print("âŒ --output ã¾ãŸã¯ --generate-all ã‚’æŒ‡å®šã—ã¦ãã ã•ã„", file=sys.stderr)
        parser.print_help()
        sys.exit(1)


if __name__ == '__main__':
    main()



