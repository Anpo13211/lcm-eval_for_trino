"""
Trino Flat-Vector Model Training Script

Trinoã‚¯ã‚¨ãƒªãƒ—ãƒ©ãƒ³å‘ã‘ã®Flat-Vectorãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã€‚
ã“ã‚Œã¯ã€æ—¢å­˜ã®PostgreSQLç”¨Flat-Vectorãƒ¢ãƒ‡ãƒ«ã‚’trinoå‘ã‘ã«å†å®Ÿè£…ã—ãŸã‚‚ã®ã§ã™ã€‚

Usage:
    # ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰å®Ÿè¡Œ
    python -m trino_lcm.scripts.train_flat_vector \
        --train_files accidents_valid_verbose.txt \
        --test_file accidents_valid_verbose.txt \
        --output_dir models/trino_flat_vector \
        --epochs 1000
"""

import sys
import os
from pathlib import Path
import argparse
import json
from typing import Optional, Sequence
import numpy as np
import torch

# ç’°å¢ƒå¤‰æ•°ã®è¨­å®šï¼ˆå¿…é ˆ - importå‰ã«å®Ÿè¡Œï¼‰
for i in range(11):
    env_key = f'NODE{i:02d}'
    env_value = os.environ.get(env_key)
    if env_value in (None, '', 'None'):
        os.environ[env_key] = '[]'

# ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒsrc/trino_lcm/scripts/ã«ã‚ã‚‹å ´åˆã€src/ã‚’è¦ªãƒ‘ã‚¹ã«è¿½åŠ 
script_dir = Path(__file__).resolve().parent
src_dir = script_dir.parent.parent
if str(src_dir) not in sys.path:
    sys.path.insert(0, str(src_dir))

from trino_lcm.models.flat_vector import (
    load_trino_plans_from_files,
    collect_operator_types,
    create_flat_vector_dataset,
    train_flat_vector_model,
    predict_flat_vector_model
)
from training.training.metrics import QError, RMSE, MAPE


def evaluate_with_metrics(bst, X, y, dataset_name="Test"):
    """
    æ—¢å­˜ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡
    
    Args:
        bst: LightGBMãƒ¢ãƒ‡ãƒ«
        X: ç‰¹å¾´é‡
        y: ãƒ©ãƒ™ãƒ«
        dataset_name: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå
    
    Returns:
        è©•ä¾¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¾žæ›¸
    """
    # äºˆæ¸¬
    y_pred = predict_flat_vector_model(bst, X)
    
    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®å®šç¾©
    metrics = [
        RMSE(),
        MAPE(),
        QError(percentile=50, early_stopping_metric=True),
        QError(percentile=95),
        QError(percentile=99),
        QError(percentile=100)
    ]
    
    # è©•ä¾¡å®Ÿè¡Œ
    metrics_dict = {}
    for metric in metrics:
        metric.evaluate(
            metrics_dict=metrics_dict,
            model=None,
            labels=y,
            preds=y_pred,
            probs=None
        )
    
    # çµæžœã‚’æ•´å½¢
    results = {
        'dataset': dataset_name,
        'num_samples': len(y),
        'rmse': metrics_dict.get('val_mse', 0.0),
        'mape': metrics_dict.get('val_mape', 0.0),
        'median_q_error': metrics_dict.get('val_median_q_error_50', 0.0),
        'p95_q_error': metrics_dict.get('val_median_q_error_95', 0.0),
        'p99_q_error': metrics_dict.get('val_median_q_error_99', 0.0),
        'max_q_error': metrics_dict.get('val_median_q_error_100', 0.0)
    }
    
    print(f"\nðŸ“Š ã€{dataset_name}ã‚»ãƒƒãƒˆè©•ä¾¡çµæžœã€‘")
    print(f"  - ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(y)}")
    print(f"  - RMSE: {results['rmse']:.4f}ç§’ ({results['rmse']*1000:.2f}ms)")
    print(f"  - MAPE: {results['mape']:.4f}")
    print(f"  - Median Q-Error: {results['median_q_error']:.4f}")
    print(f"  - P95 Q-Error: {results['p95_q_error']:.4f}")
    print(f"  - P99 Q-Error: {results['p99_q_error']:.4f}")
    print(f"  - Max Q-Error: {results['max_q_error']:.4f}")
    
    return results


def build_parser() -> argparse.ArgumentParser:
    """Build the argument parser for Flat-Vector training."""
    parser = argparse.ArgumentParser(
        description='Train Trino Flat-Vector Model (Trinoå‘ã‘å†å®Ÿè£…ç‰ˆ)'
    )
    
    # ãƒ‡ãƒ¼ã‚¿é–¢é€£ã®å¼•æ•°
    parser.add_argument('--train_files', type=str, required=True,
                        help='ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆã‚«ãƒ³ãƒžåŒºåˆ‡ã‚Šï¼‰')
    parser.add_argument('--test_file', type=str, required=True,
                        help='ãƒ†ã‚¹ãƒˆç”¨ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹')
    
    # ãƒ¢ãƒ‡ãƒ«é–¢é€£ã®å¼•æ•°
    parser.add_argument('--output_dir', type=str, default='models/trino_flat_vector',
                        help='ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    parser.add_argument('--num_boost_round', type=int, default=1000,
                        help='ãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰æ•°')
    parser.add_argument('--early_stopping_rounds', type=int, default=20,
                        help='æ—©æœŸåœæ­¢ãƒ©ã‚¦ãƒ³ãƒ‰æ•°')
    parser.add_argument('--seed', type=int, default=42,
                        help='ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰')
    
    # ãƒ‡ãƒ¼ã‚¿å‡¦ç†é–¢é€£ã®å¼•æ•°
    parser.add_argument('--max_plans_per_file', type=int, default=None,
                        help='å„ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€æœ€å¤§ãƒ—ãƒ©ãƒ³æ•°')
    parser.add_argument('--val_ratio', type=float, default=0.15,
                        help='æ¤œè¨¼ã‚»ãƒƒãƒˆã®å‰²åˆ')
    parser.add_argument('--use_act_card', action='store_true',
                        help='å®Ÿéš›ã®ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£ã‚’ä½¿ç”¨ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: æŽ¨å®šã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£ï¼‰')
    
    return parser


def run(args) -> int:
    """Run Flat-Vector training with parsed arguments."""
    
    # ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰ã®è¨­å®š
    np.random.seed(args.seed)
    torch.manual_seed(args.seed)
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print("=" * 80)
    print("Trino Flat-Vector Model Training")
    print("ï¼ˆPostgreSQLç”¨Flat-Vectorãƒ¢ãƒ‡ãƒ«ã®trinoå‘ã‘å†å®Ÿè£…ï¼‰")
    print("=" * 80)
    print(f"Train files: {args.train_files}")
    print(f"Test file: {args.test_file}")
    print(f"Output directory: {args.output_dir}")
    print(f"Use actual cardinality: {args.use_act_card}")
    print()
    
    # 1. ãƒ—ãƒ©ãƒ³ã®èª­ã¿è¾¼ã¿
    print("ðŸ“‚ ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ—ãƒ©ãƒ³ã®èª­ã¿è¾¼ã¿")
    train_file_paths = [Path(p.strip()) for p in args.train_files.split(',')]
    test_file_path = Path(args.test_file)
    
    # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ—ãƒ©ãƒ³ã®èª­ã¿è¾¼ã¿
    train_plans = load_trino_plans_from_files(train_file_paths, args.max_plans_per_file)
    
    # ãƒ†ã‚¹ãƒˆãƒ—ãƒ©ãƒ³ã®èª­ã¿è¾¼ã¿
    test_plans = load_trino_plans_from_files([test_file_path], args.max_plans_per_file)
    
    print()
    
    # 2. æ¼”ç®—å­ã‚¿ã‚¤ãƒ—ã®åŽé›†
    print("ðŸ“Š ã‚¹ãƒ†ãƒƒãƒ—2: æ¼”ç®—å­ã‚¿ã‚¤ãƒ—ã®åŽé›†")
    op_idx_dict = collect_operator_types(train_plans)
    print()
    
    # 3. ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°/æ¤œè¨¼ã‚»ãƒƒãƒˆã®åˆ†å‰²
    print("ðŸ“Š ã‚¹ãƒ†ãƒƒãƒ—3: ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°/æ¤œè¨¼ã‚»ãƒƒãƒˆã®åˆ†å‰²")
    val_size = int(len(train_plans) * args.val_ratio)
    train_size = len(train_plans) - val_size
    
    # ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ£ãƒƒãƒ•ãƒ«
    indices = list(range(len(train_plans)))
    np.random.shuffle(indices)
    
    train_indices = indices[:train_size]
    val_indices = indices[train_size:]
    
    train_plans_split = [train_plans[i] for i in train_indices]
    val_plans_split = [train_plans[i] for i in val_indices]
    
    print(f"  - ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ—ãƒ©ãƒ³: {len(train_plans_split)}")
    print(f"  - æ¤œè¨¼ãƒ—ãƒ©ãƒ³: {len(val_plans_split)}")
    print(f"  - ãƒ†ã‚¹ãƒˆãƒ—ãƒ©ãƒ³: {len(test_plans)}")
    print()
    
    # 4. ç‰¹å¾´é‡ã®æŠ½å‡º
    print("ðŸ”§ ã‚¹ãƒ†ãƒƒãƒ—4: ç‰¹å¾´é‡ã®æŠ½å‡º")
    
    print("  - ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚»ãƒƒãƒˆ...")
    X_train, y_train = create_flat_vector_dataset(train_plans_split, op_idx_dict, args.use_act_card)
    
    print("  - æ¤œè¨¼ã‚»ãƒƒãƒˆ...")
    X_val, y_val = create_flat_vector_dataset(val_plans_split, op_idx_dict, args.use_act_card, verbose=False)
    
    print("  - ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆ...")
    X_test, y_test = create_flat_vector_dataset(test_plans, op_idx_dict, args.use_act_card, verbose=False)
    
    print(f"\n  - ç‰¹å¾´é‡æ¬¡å…ƒæ•°: {X_train.shape[1]}")
    print(f"  - ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚µãƒ³ãƒ—ãƒ«: {len(X_train)}")
    print(f"  - æ¤œè¨¼ã‚µãƒ³ãƒ—ãƒ«: {len(X_val)}")
    print(f"  - ãƒ†ã‚¹ãƒˆã‚µãƒ³ãƒ—ãƒ«: {len(X_test)}")
    print()
    
    # 5. ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°
    print("ðŸš€ ã‚¹ãƒ†ãƒƒãƒ—5: ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°")
    bst = train_flat_vector_model(
        X_train, y_train,
        X_val, y_val,
        num_boost_round=args.num_boost_round,
        early_stopping_rounds=args.early_stopping_rounds,
        seed=args.seed,
        verbose=True
    )
    
    # ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜
    model_path = output_dir / f'flat_vector_model_{args.seed}.txt'
    bst.save_model(str(model_path))
    print(f"âœ… ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜: {model_path}")
    print()
    
    # 6. ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡
    print("ðŸ“Š ã‚¹ãƒ†ãƒƒãƒ—6: ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡")
    
    # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚»ãƒƒãƒˆã§ã®è©•ä¾¡
    train_metrics = evaluate_with_metrics(bst, X_train, y_train, "Train")
    
    # æ¤œè¨¼ã‚»ãƒƒãƒˆã§ã®è©•ä¾¡
    val_metrics = evaluate_with_metrics(bst, X_val, y_val, "Validation")
    
    # ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã§ã®è©•ä¾¡
    test_metrics = evaluate_with_metrics(bst, X_test, y_test, "Test")
    
    # 7. çµæžœã®ä¿å­˜
    print("\nðŸ’¾ ã‚¹ãƒ†ãƒƒãƒ—7: çµæžœã®ä¿å­˜")
    
    # æ¼”ç®—å­ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¾žæ›¸ã®ä¿å­˜
    op_idx_path = output_dir / f'op_idx_dict_{args.seed}.json'
    with open(op_idx_path, 'w') as f:
        json.dump(op_idx_dict, f, indent=2)
    print(f"  - æ¼”ç®—å­ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¾žæ›¸: {op_idx_path}")
    
    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ä¿å­˜
    metrics_path = output_dir / f'metrics_{args.seed}.json'
    with open(metrics_path, 'w') as f:
        json.dump({
            'train': train_metrics,
            'validation': val_metrics,
            'test': test_metrics,
            'hyperparameters': {
                'num_boost_round': args.num_boost_round,
                'early_stopping_rounds': args.early_stopping_rounds,
                'val_ratio': args.val_ratio,
                'use_act_card': args.use_act_card,
                'seed': args.seed
            }
        }, f, indent=2)
    print(f"  - ãƒ¡ãƒˆãƒªã‚¯ã‚¹: {metrics_path}")
    
    print()
    print("=" * 80)
    print("ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†ï¼")
    print(f"Validation Median Q-Error: {val_metrics['median_q_error']:.4f}")
    print(f"Test Median Q-Error: {test_metrics['median_q_error']:.4f}")
    print(f"Model saved to: {model_path}")
    print("=" * 80)
    
    return 0


def main(argv: Optional[Sequence[str]] = None) -> int:
    """Main entry point for Flat-Vector training."""
    parser = build_parser()
    args = parser.parse_args(argv)
    return run(args)


if __name__ == "__main__":
    from typing import Optional, Sequence
    import sys
    sys.exit(main())

