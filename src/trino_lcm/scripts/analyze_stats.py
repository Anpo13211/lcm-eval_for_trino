"""
Trinoçµ±è¨ˆæƒ…å ±åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ

collect_stats.pyã§åé›†ã—ãŸçµ±è¨ˆæƒ…å ±ã‚’åˆ†æã—ã¦ã€ç‰¹å¾´é‡ã‚’æŠ½å‡ºã—ã¾ã™ã€‚

Usage:
    # ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰å®Ÿè¡Œ
    python -m trino_lcm.scripts.analyze_stats \
        --stats_dir datasets_statistics/iceberg_imdb
"""

import json
import sys
from typing import Dict, Any


def analyze_column_stats(col_stats: Dict[str, Any]) -> Dict[str, Any]:
    """ã‚«ãƒ©ãƒ çµ±è¨ˆã‹ã‚‰æœ‰ç”¨ãªç‰¹å¾´é‡ã‚’æŠ½å‡º"""
    features = {
        'column_name': col_stats['column_name'],
        
        # æ•°å€¤ç‰¹å¾´
        'data_size': col_stats.get('data_size'),  # ãƒã‚¤ãƒˆå˜ä½ã®ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º
        'distinct_values_count': col_stats.get('distinct_values_count'),  # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå€¤ã®æ•°
        'nulls_fraction': col_stats.get('nulls_fraction'),  # NULLå€¤ã®å‰²åˆï¼ˆ0~1ï¼‰
        
        # ç¯„å›²ç‰¹å¾´ï¼ˆæ•°å€¤ã‚«ãƒ©ãƒ ã®å ´åˆã®ã¿ï¼‰
        'low_value': col_stats.get('low_value'),  # æœ€å°å€¤
        'high_value': col_stats.get('high_value'),  # æœ€å¤§å€¤
        
        # æ´¾ç”Ÿç‰¹å¾´
        'avg_value_size': None,  # 1å€¤ã‚ãŸã‚Šã®å¹³å‡ã‚µã‚¤ã‚º
        'cardinality_ratio': None,  # distinct / row_countï¼ˆé¸æŠæ€§ã®æŒ‡æ¨™ï¼‰
    }
    
    return features


def compute_derived_features(
    table_stats: Dict[str, Any],
    col_features: Dict[str, Any]
) -> Dict[str, Any]:
    """æ´¾ç”Ÿç‰¹å¾´é‡ã‚’è¨ˆç®—"""
    row_count = table_stats.get('row_count')
    data_size = col_features.get('data_size')
    distinct_count = col_features.get('distinct_values_count')
    
    # 1å€¤ã‚ãŸã‚Šã®å¹³å‡ã‚µã‚¤ã‚º
    if data_size is not None and row_count and row_count > 0:
        col_features['avg_value_size'] = data_size / row_count
    
    # ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£æ¯”ç‡ï¼ˆé¸æŠæ€§ï¼‰
    if distinct_count is not None and row_count and row_count > 0:
        col_features['cardinality_ratio'] = distinct_count / row_count
    
    return col_features


def compare_with_postgres_features():
    """Postgres zero-shotã§ä½¿ã‚ã‚Œã¦ã„ã‚‹ç‰¹å¾´é‡ã¨ã®æ¯”è¼ƒ"""
    print("\nğŸ“Š Postgres zero-shotã§ä½¿ã‚ã‚Œã¦ã„ã‚‹ã‚«ãƒ©ãƒ ç‰¹å¾´é‡:")
    print("=" * 70)
    
    postgres_features = [
        ('avg_width', 'å¹³å‡ã‚«ãƒ©ãƒ å¹…ï¼ˆãƒã‚¤ãƒˆï¼‰'),
        ('correlation', 'ç‰©ç†çš„é †åºã¨ã®ç›¸é–¢'),
        ('n_distinct', 'ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå€¤ã®æ•°ï¼ˆæ¨å®šï¼‰'),
        ('null_frac', 'NULLå€¤ã®å‰²åˆ'),
        ('min_val', 'æœ€å°å€¤'),
        ('max_val', 'æœ€å¤§å€¤'),
        ('num_rows', 'ãƒ†ãƒ¼ãƒ–ãƒ«ã®è¡Œæ•°'),
    ]
    
    for feat, desc in postgres_features:
        print(f"  - {feat:20s}: {desc}")
    
    print("\nğŸ”„ Trinoã®çµ±è¨ˆæƒ…å ±ã¨ã®ãƒãƒƒãƒ”ãƒ³ã‚°:")
    print("=" * 70)
    
    mappings = [
        ('avg_width', 'avg_value_size', 'âœ… data_size / row_count ã§è¨ˆç®—å¯èƒ½'),
        ('correlation', 'N/A', 'âŒ Trinoã§ã¯å–å¾—ä¸å¯'),
        ('n_distinct', 'distinct_values_count', 'âœ… ç›´æ¥å–å¾—å¯èƒ½'),
        ('null_frac', 'nulls_fraction', 'âœ… ç›´æ¥å–å¾—å¯èƒ½'),
        ('min_val', 'low_value', 'âœ… ç›´æ¥å–å¾—å¯èƒ½ï¼ˆæ•°å€¤ã®ã¿ï¼‰'),
        ('max_val', 'high_value', 'âœ… ç›´æ¥å–å¾—å¯èƒ½ï¼ˆæ•°å€¤ã®ã¿ï¼‰'),
        ('num_rows', 'row_count', 'âœ… ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ¬ãƒ™ãƒ«ã§å–å¾—å¯èƒ½'),
    ]
    
    for pg_feat, trino_feat, status in mappings:
        print(f"  {pg_feat:20s} â†’ {trino_feat:30s} {status}")
    
    print("\nâ• Trinoå›ºæœ‰ã®è¿½åŠ ç‰¹å¾´é‡:")
    print("=" * 70)
    
    trino_extras = [
        ('data_size', 'ã‚«ãƒ©ãƒ å…¨ä½“ã®ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºï¼ˆãƒã‚¤ãƒˆï¼‰'),
        ('cardinality_ratio', 'distinct_count / row_countï¼ˆé¸æŠæ€§æŒ‡æ¨™ï¼‰'),
    ]
    
    for feat, desc in trino_extras:
        print(f"  + {feat:20s}: {desc}")


def main():
    if len(sys.argv) < 2:
        stats_file = 'trino_statistics.json'
    else:
        stats_file = sys.argv[1]
    
    print(f"ğŸ“– çµ±è¨ˆæƒ…å ±ãƒ•ã‚¡ã‚¤ãƒ«: {stats_file}")
    
    try:
        with open(stats_file, 'r', encoding='utf-8') as f:
            stats = json.load(f)
    except FileNotFoundError:
        print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {stats_file}")
        sys.exit(1)
    
    catalog = stats.get('catalog')
    schema = stats.get('schema')
    tables = stats.get('tables', {})
    
    print(f"ğŸ“Š Catalog: {catalog}, Schema: {schema}")
    print(f"ğŸ“Š ãƒ†ãƒ¼ãƒ–ãƒ«æ•°: {len(tables)}\n")
    
    # å„ãƒ†ãƒ¼ãƒ–ãƒ«ã®çµ±è¨ˆæƒ…å ±ã‚’åˆ†æ
    for table_name, table_stats in tables.items():
        print(f"\n{'='*70}")
        print(f"ğŸ“‹ ãƒ†ãƒ¼ãƒ–ãƒ«: {table_name}")
        print(f"{'='*70}")
        
        row_count = table_stats.get('row_count')
        columns = table_stats.get('columns', {})
        
        print(f"  è¡Œæ•°: {int(row_count):,}" if row_count else "  è¡Œæ•°: N/A")
        print(f"  ã‚«ãƒ©ãƒ æ•°: {len(columns)}")
        print()
        
        print(f"{'ã‚«ãƒ©ãƒ å':<25} {'Distinct':<12} {'Nulls':<10} "
              f"{'Avg Size':<12} {'Cardinality':<15}")
        print("-" * 80)
        
        for col_name, col_stats in columns.items():
            # ç‰¹å¾´é‡ã‚’æŠ½å‡ºãƒ»è¨ˆç®—
            features = analyze_column_stats(col_stats)
            features = compute_derived_features(table_stats, features)
            
            distinct = features.get('distinct_values_count')
            nulls = features.get('nulls_fraction')
            avg_size = features.get('avg_value_size')
            cardinality = features.get('cardinality_ratio')
            
            distinct_str = f"{int(distinct):,}" if distinct else "N/A"
            nulls_str = f"{nulls:.2%}" if nulls is not None else "N/A"
            avg_size_str = f"{avg_size:.1f}B" if avg_size else "N/A"
            card_str = f"{cardinality:.4f}" if cardinality else "N/A"
            
            print(f"{col_name:<25} {distinct_str:<12} {nulls_str:<10} "
                  f"{avg_size_str:<12} {card_str:<15}")
        
        print()
        
        # é¸æŠæ€§ã®é«˜ã„ã‚«ãƒ©ãƒ ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å€™è£œï¼‰ã‚’è¡¨ç¤º
        high_card_cols = []
        for col_name, col_stats in columns.items():
            features = analyze_column_stats(col_stats)
            features = compute_derived_features(table_stats, features)
            cardinality = features.get('cardinality_ratio')
            
            if cardinality and cardinality > 0.9:  # 90%ä»¥ä¸ŠãŒãƒ¦ãƒ‹ãƒ¼ã‚¯
                high_card_cols.append((col_name, cardinality))
        
        if high_card_cols:
            print("  ğŸ”‘ é«˜é¸æŠæ€§ã‚«ãƒ©ãƒ ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å€™è£œï¼‰:")
            for col_name, card in sorted(high_card_cols, key=lambda x: -x[1]):
                print(f"    - {col_name}: {card:.4f}")
        
        # NULLå€¤ã®å¤šã„ã‚«ãƒ©ãƒ ã‚’è¡¨ç¤º
        high_null_cols = []
        for col_name, col_stats in columns.items():
            nulls = col_stats.get('nulls_fraction')
            if nulls and nulls > 0.5:  # 50%ä»¥ä¸ŠãŒNULL
                high_null_cols.append((col_name, nulls))
        
        if high_null_cols:
            print("  âš ï¸  NULLå€¤ã®å¤šã„ã‚«ãƒ©ãƒ :")
            for col_name, nulls in sorted(high_null_cols, key=lambda x: -x[1]):
                print(f"    - {col_name}: {nulls:.2%}")
    
    # Postgresç‰¹å¾´é‡ã¨ã®æ¯”è¼ƒ
    compare_with_postgres_features()
    
    print("\n" + "=" * 70)
    print("âœ… åˆ†æå®Œäº†")
    print("=" * 70)
    print("\nğŸ’¡ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print("  1. trino_plan_batching.py ã® column ç‰¹å¾´é‡ã«ã“ã‚Œã‚‰ã®çµ±è¨ˆæƒ…å ±ã‚’è¿½åŠ ")
    print("  2. create_dummy_feature_statistics() ã‚’å®Ÿçµ±è¨ˆã§ç½®ãæ›ãˆ")
    print("  3. RobustScaler ã§æ­£è¦åŒ–ã—ã¦ãƒ¢ãƒ‡ãƒ«ã«å…¥åŠ›")


if __name__ == '__main__':
    main()

