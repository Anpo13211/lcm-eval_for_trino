"""
Trino Zero-Shot Model Training Script

Trinoã‚¯ã‚¨ãƒªãƒ—ãƒ©ãƒ³å‘ã‘ã®Zero-Shotãƒ¢ãƒ‡ãƒ«ï¼ˆGraph Neural Networkï¼‰ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã€‚

Usage:
    # ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰å®Ÿè¡Œ
    python -m trino_lcm.scripts.train_zeroshot \
        --train_files accidents_valid_verbose.txt \
        --test_file accidents_valid_verbose.txt \
        --output_dir models/trino_zeroshot \
        --statistics_dir datasets_statistics \
        --catalog iceberg \
        --schema imdb
"""

import sys
import os
import warnings

# Suppress torchdata deprecation warnings
warnings.filterwarnings('ignore', category=UserWarning, module='torchdata')

# ç’°å¢ƒå¤‰æ•°ã®è¨­å®šï¼ˆå¿…é ˆ - importå‰ã«å®Ÿè¡Œï¼‰
for i in range(11):
    env_key = f'NODE{i:02d}'
    env_value = os.environ.get(env_key)
    # `.env` ã§ "None" ã‚„ç©ºæ–‡å­—ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã¨ ast.literal_eval ãŒå¤±æ•—ã™ã‚‹ãŸã‚æ˜ç¤ºçš„ã«åˆæœŸåŒ–ã™ã‚‹
    if env_value in (None, '', 'None'):
        os.environ[env_key] = '[]'

# ZERO_SHOT_DATASETS_DIRç’°å¢ƒå¤‰æ•°ã®è¨­å®šï¼ˆcolumn_statistics.jsonã‹ã‚‰çµ±è¨ˆæƒ…å ±ã‚’å–å¾—ã™ã‚‹ãŸã‚ï¼‰
# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ã‚¹ã‚’è¨­å®šï¼ˆç’°å¢ƒå¤‰æ•°ãŒæ—¢ã«è¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ä¸Šæ›¸ãã—ãªã„ï¼‰
if 'ZERO_SHOT_DATASETS_DIR' not in os.environ:
    default_zero_shot_dir = '/Users/an/query_engine/lakehouse/zero-shot_datasets'
    if os.path.exists(default_zero_shot_dir):
        os.environ['ZERO_SHOT_DATASETS_DIR'] = default_zero_shot_dir
        print(f"â„¹ï¸  ZERO_SHOT_DATASETS_DIR ã‚’è¨­å®šã—ã¾ã—ãŸ: {default_zero_shot_dir}")

# ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒsrc/trino_lcm/scripts/ã«ã‚ã‚‹å ´åˆã€src/ã‚’è¦ªãƒ‘ã‚¹ã«è¿½åŠ 
from pathlib import Path
script_dir = Path(__file__).resolve().parent
src_dir = script_dir.parent.parent
if str(src_dir) not in sys.path:
    sys.path.insert(0, str(src_dir))

import argparse
import json
import re
import functools
from pathlib import Path
from typing import Optional, Sequence
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, Dataset, random_split
import numpy as np
from tqdm import tqdm

from cross_db_benchmark.benchmark_tools.trino.parse_plan import parse_trino_plans, trino_timing_regex
from trino_lcm.models.zero_shot import trino_plan_collator, load_database_statistics
from models.zeroshot.zero_shot_model import ZeroShotModel
from training.featurizations import TrinoTrueCardDetail
from classes.classes import ZeroShotModelConfig
from training.preprocessing.feature_statistics import gather_feature_statistics, FeatureType
from training.training.metrics import QError, RMSE


class TrinoPlanDataset(Dataset):
    """Trinoã‚¯ã‚¨ãƒªãƒ—ãƒ©ãƒ³ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ"""
    
    def __init__(self, plans):
        """
        Args:
            plans: TrinoPlanOperatorã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ãƒªã‚¹ãƒˆ
        """
        self.plans = plans
    
    def __len__(self):
        return len(self.plans)
    
    def __getitem__(self, idx):
        return idx, self.plans[idx]


class MockQuery:
    """ãƒ¢ãƒƒã‚¯ã®Queryã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, plan_text):
        self.plan_text = plan_text
        self.timeout = False
        self.analyze_plans = [plan_text]  # parse_trino_plansãŒæœŸå¾…ã™ã‚‹å½¢å¼
        
        # verbose_planã¯æ–‡å­—åˆ—å½¢å¼ã§æä¾›ï¼ˆparse_trino_raw_plan_v2ãŒæœŸå¾…ã™ã‚‹å½¢å¼ï¼‰
        self.verbose_plan = plan_text
        
        # SQLæ–‡ã‚’æŠ½å‡ºï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ã€ãƒ—ãƒ©ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æŠ½å‡ºã‚’è©¦ã¿ã‚‹ï¼‰
        # æœ€åˆã®'-- stmt'ã§å§‹ã¾ã‚‹è¡Œã‚’æ¢ã™
        sql_lines = []
        for line in plan_text.split('\n'):
            if line.strip().startswith('-- stmt'):
                # SQLæ–‡ã®è¡Œã‚’æŠ½å‡ºï¼ˆæ¬¡ã®è¡Œã‹ã‚‰ï¼‰
                sql_lines = []
            elif sql_lines is not None and line.strip() and not line.strip().startswith('--'):
                sql_lines.append(line.strip())
                if sql_lines and line.strip().endswith(';'):
                    break
        self.sql = ' '.join(sql_lines) if sql_lines else 'SELECT * FROM unknown'  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®SQL
        
        # å®Ÿè¡Œæ™‚é–“ã‚’æŠ½å‡º
        execution_time = None
        
        timing_match = trino_timing_regex.search(plan_text)
        if timing_match:
            # æ­£è¦è¡¨ç¾ã®ã‚°ãƒ«ãƒ¼ãƒ—: 1=Queuedå€¤, 2=Queuedå˜ä½, 3=Analysiså€¤, 4=Analysiså˜ä½,
            # 5=Planningå€¤, 6=Planningå˜ä½, 7=Executionå€¤, 8=Executionå˜ä½
            execution_time = float(timing_match.group(7))  # Executionå€¤
            execution_unit = timing_match.group(8)  # Executionå˜ä½
            if execution_unit and execution_unit == 's':
                execution_time *= 1000
            elif execution_unit and execution_unit in ('us', 'Î¼s'):
                execution_time /= 1000
            elif execution_unit and execution_unit == 'm':
                execution_time *= 60000
        
        if execution_time is None:
            # å¤ã„æ›¸å¼ ("Execution Time: <value><unit>") ã«ã‚‚å¯¾å¿œ
            execution_time_match = re.search(r'Execution(?: Time)?: ([\d.]+)(ms|s)', plan_text)
            if execution_time_match:
                execution_time = float(execution_time_match.group(1))
                if execution_time_match.group(2) == 's':
                    execution_time *= 1000
        
        self.execution_time = execution_time if execution_time is not None else 1000.0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®å®Ÿè¡Œæ™‚é–“ï¼ˆãƒŸãƒªç§’ï¼‰


class MockRunStats:
    """ãƒ¢ãƒƒã‚¯ã®RunStatsã‚¯ãƒ©ã‚¹ï¼ˆãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ç”¨ï¼‰"""
    
    def __init__(self, plans_text):
        self.plans_text = plans_text
        # parse_trino_plansã§å¿…è¦ãªå±æ€§ã‚’è¿½åŠ 
        self.query_list = [MockQuery(plan_text) for plan_text in plans_text]
        
        # database_statsã‚’SimpleNamespaceå½¢å¼ã§åˆæœŸåŒ–ï¼ˆparse_trino_plans_v2ãŒæœŸå¾…ã™ã‚‹å½¢å¼ï¼‰
        from types import SimpleNamespace
        self.database_stats = SimpleNamespace(
            table_stats=[],  # ãƒªã‚¹ãƒˆå½¢å¼
            column_stats=[]  # ãƒªã‚¹ãƒˆå½¢å¼
        )
        
        # run_kwargsã‚’è¿½åŠ ï¼ˆparse_trino_plans_v2ãŒæœŸå¾…ã™ã‚‹å½¢å¼ï¼‰
        self.run_kwargs = {}
    
    def __iter__(self):
        for plan_text in self.plans_text:
            yield plan_text


def split_query_plans(file_path):
    """ã‚¯ã‚¨ãƒªãƒ—ãƒ©ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å€‹åˆ¥ã®ãƒ—ãƒ©ãƒ³ã«åˆ†å‰²"""
    with open(file_path, 'r') as f:
        content = f.read()
    
    # ã‚¯ã‚¨ãƒªãƒ—ãƒ©ãƒ³ã‚’åˆ†å‰²
    plans_text = []
    current_plan = []
    
    for line in content.split('\n'):
        if line.startswith('-- ') and 'stmt' in line and current_plan:
            plans_text.append('\n'.join(current_plan))
            current_plan = [line]
        else:
            current_plan.append(line)
    
    if current_plan:
        plans_text.append('\n'.join(current_plan))
    
    return plans_text


def load_plans_from_files(file_paths, max_plans_per_file=None):
    """
    è¤‡æ•°ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ—ãƒ©ãƒ³ã‚’èª­ã¿è¾¼ã¿
    
    Args:
        file_paths: ãƒ—ãƒ©ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆ
        max_plans_per_file: å„ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€æœ€å¤§ãƒ—ãƒ©ãƒ³æ•°
    
    Returns:
        å…¨ãƒ—ãƒ©ãƒ³ã®ãƒªã‚¹ãƒˆ
    """
    all_plans = []
    
    print(f"ğŸ“‚ {len(file_paths)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ—ãƒ©ãƒ³ã‚’èª­ã¿è¾¼ã¿ä¸­...")
    
    for file_idx, file_path in enumerate(tqdm(file_paths, desc="ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿")):
        # JSONãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆ
        if str(file_path).endswith('.json'):
            with open(file_path, 'r') as f:
                run_data = json.load(f)
            
            # parse_trino_plansã‚’ä½¿ç”¨ã—ã¦ãƒ—ãƒ©ãƒ³ã‚’è§£æ
            # TODO: JSONã‹ã‚‰run_statsã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å†æ§‹ç¯‰
            pass
        
        # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆï¼ˆEXPLAIN ANALYZEå‡ºåŠ›ï¼‰
        else:
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§å€‹åˆ¥ã®ã‚¯ã‚¨ãƒªãƒ—ãƒ©ãƒ³ã«åˆ†å‰²
            with open(file_path, 'r') as f:
                content = f.read()
            
            # ã‚¯ã‚¨ãƒªãƒ—ãƒ©ãƒ³ã‚’åˆ†å‰²
            plans_text = []
            current_plan = []
            
            for line in content.split('\n'):
                if line.startswith('-- ') and 'stmt' in line and current_plan:
                    plans_text.append('\n'.join(current_plan))
                    current_plan = [line]
                else:
                    current_plan.append(line)
            
            if current_plan:
                plans_text.append('\n'.join(current_plan))
            
            # æœ€å¤§ãƒ—ãƒ©ãƒ³æ•°ã‚’åˆ¶é™
            if max_plans_per_file:
                plans_text = plans_text[:max_plans_per_file]
            
            print(f"  - {file_path}: {len(plans_text)}å€‹ã®ãƒ—ãƒ©ãƒ³ã‚’æ¤œå‡º")
            
            # MockRunStatsã‚’ä½œæˆã—ã¦ãƒ‘ãƒ¼ã‚¹
            mock_stats = MockRunStats(plans_text)
            
            # parse_trino_plans_v2ã‚’ä½¿ç”¨ï¼ˆçµ±è¨ˆæƒ…å ±ã«å¯¾å¿œï¼‰
            from cross_db_benchmark.benchmark_tools.trino.parse_plan import parse_trino_plans_v2
            
            # çµ±è¨ˆæƒ…å ±ã‚’èª­ã¿è¾¼ã‚“ã§database_statsã«è¨­å®šï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            # æ³¨æ„: çµ±è¨ˆæƒ…å ±ãŒãªã„å ´åˆã¯ç©ºã®ãƒªã‚¹ãƒˆã§å‹•ä½œã™ã‚‹
            # çµ±è¨ˆæƒ…å ±ã®èª­ã¿è¾¼ã¿ã§ã¯ãƒ—ãƒ©ãƒ³æ•°ã«åˆ¶é™ã‚’ã‹ã‘ãªã„ï¼ˆNoneã‚’æ¸¡ã™ï¼‰
            try:
                from training.dataset.dataset_creation import read_explain_analyze_txt
                _, db_stats_from_txt = read_explain_analyze_txt(
                    file_path,
                    path_index=file_idx,
                    limit_per_ds=None  # çµ±è¨ˆæƒ…å ±ã¯å…¨ã‚¯ã‚¨ãƒªã‹ã‚‰å–å¾—ï¼ˆãƒ—ãƒ©ãƒ³èª­ã¿è¾¼ã¿ã¨ã¯ç‹¬ç«‹ï¼‰
                )
                # database_statsã‚’æ›´æ–°ï¼ˆãƒªã‚¹ãƒˆå½¢å¼ã«å¤‰æ›ï¼‰
                from types import SimpleNamespace
                mock_stats.database_stats = SimpleNamespace(
                    table_stats=list(db_stats_from_txt.table_stats.values()) if isinstance(db_stats_from_txt.table_stats, dict) else [],
                    column_stats=list(db_stats_from_txt.column_stats.values()) if isinstance(db_stats_from_txt.column_stats, dict) else []
                )
            except Exception as e:
                print(f"  âš ï¸  çµ±è¨ˆæƒ…å ±ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ï¼ˆçµ±è¨ˆæƒ…å ±ãªã—ã§ç¶šè¡Œï¼‰: {e}")
            
            parsed_runs, _ = parse_trino_plans_v2(
                mock_stats,
                min_runtime=0,
                max_runtime=1000000,
                parse_baseline=False,
                include_zero_card=True
            )
            
            print(f"  - ãƒ‘ãƒ¼ã‚¹çµæœ: {len(parsed_runs['parsed_plans'])}å€‹ã®ãƒ—ãƒ©ãƒ³")
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹IDã‚’è¨­å®š
            for plan in parsed_runs['parsed_plans']:
                plan.database_id = file_idx
            
            all_plans.extend(parsed_runs['parsed_plans'])
    
    print(f"  - ç·ãƒ—ãƒ©ãƒ³æ•°: {len(all_plans)}")
    return all_plans


def create_feature_statistics_from_plans(plans, plan_featurization, output_path=None):
    """
    ãƒ—ãƒ©ãƒ³ã‹ã‚‰ç‰¹å¾´é‡çµ±è¨ˆã‚’å‹•çš„ã«åé›†
    
    Args:
        plans: TrinoPlanOperatorã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ãƒªã‚¹ãƒˆ
        plan_featurization: ç‰¹å¾´é‡åŒ–è¨­å®š
        output_path: çµ±è¨ˆæƒ…å ±ã®å‡ºåŠ›ãƒ‘ã‚¹ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    
    Returns:
        feature_statisticsè¾æ›¸
    """
    print("ğŸ“Š ãƒ—ãƒ©ãƒ³ã‹ã‚‰ç‰¹å¾´é‡çµ±è¨ˆã‚’åé›†ä¸­...")
    
    # å®Ÿéš›ã«ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹æ¼”ç®—å­ã‚’åé›†ï¼ˆop_nameç”¨ï¼‰
    actual_op_names = set()
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¼”ç®—å­ã‚‚åé›†ï¼ˆoperatorç”¨ï¼‰
    filter_operators = set()
    
    def collect_operators(node):
        if hasattr(node, 'plan_parameters'):
            params = node.plan_parameters if isinstance(node.plan_parameters, dict) else vars(node.plan_parameters)
            op_name = params.get('op_name')
            if op_name:
                actual_op_names.add(op_name)
            
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¼”ç®—å­ã‚’åé›†
            filter_col = params.get('filter_columns')
            if filter_col:
                def collect_filter_ops(filter_node):
                    # PredicateNodeã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å ´åˆ
                    if hasattr(filter_node, 'operator'):
                        op = filter_node.operator
                        if op is not None:
                            filter_operators.add(str(op))
                    # è¾æ›¸å½¢å¼ã®å ´åˆ
                    elif isinstance(filter_node, dict) and 'operator' in filter_node:
                        op = filter_node['operator']
                        if op is not None:
                            filter_operators.add(str(op))
                    
                    # å­ãƒãƒ¼ãƒ‰ã‚’å†å¸°çš„ã«å‡¦ç†ï¼ˆä¸¡å½¢å¼ã«å¯¾å¿œï¼‰
                    children = None
                    if hasattr(filter_node, 'children'):
                        children = filter_node.children
                    elif isinstance(filter_node, dict) and 'children' in filter_node:
                        children = filter_node['children']
                    
                    if children:
                        for child in children:
                            collect_filter_ops(child)
                
                collect_filter_ops(filter_col)
        
        if hasattr(node, 'children'):
            for child in node.children:
                collect_operators(child)
    
    for plan in plans:
        collect_operators(plan)
    
    print(f"  - æ¤œå‡ºã•ã‚ŒãŸãƒ—ãƒ©ãƒ³æ¼”ç®—å­ (op_name): {sorted(actual_op_names)}")
    print(f"  - æ¤œå‡ºã•ã‚ŒãŸãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¼”ç®—å­ (operator): {sorted(filter_operators)}")
    
    # ãƒ€ãƒŸãƒ¼ã®çµ±è¨ˆæƒ…å ±ã‹ã‚‰é–‹å§‹ï¼ˆå®Ÿéš›ã®æ¼”ç®—å­ã‚’å«ã‚€ã‚ˆã†ã«æ›´æ–°ï¼‰
    feature_statistics = create_dummy_feature_statistics(
        plan_featurization, 
        actual_op_names=actual_op_names if actual_op_names else None,
        filter_operators=filter_operators if filter_operators else None
    )
    
    if output_path:
        with open(output_path, 'w') as f:
            json.dump(feature_statistics, f, indent=2)
        print(f"  - ç‰¹å¾´é‡çµ±è¨ˆã‚’ {output_path} ã«ä¿å­˜")
    
    return feature_statistics


def create_dummy_feature_statistics(plan_featurization, actual_op_names=None, filter_operators=None):
    """
    ãƒ€ãƒŸãƒ¼ã®ç‰¹å¾´é‡çµ±è¨ˆæƒ…å ±ã‚’ä½œæˆ
    
    Args:
        plan_featurization: ç‰¹å¾´é‡åŒ–è¨­å®š
        actual_op_names: å®Ÿéš›ã«ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ãƒ—ãƒ©ãƒ³æ¼”ç®—å­ã®ã‚»ãƒƒãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        filter_operators: å®Ÿéš›ã«ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¼”ç®—å­ã®ã‚»ãƒƒãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    """
    feature_statistics = {}
    
    # ã™ã¹ã¦ã®ç‰¹å¾´é‡ã‚’å®šç¾©
    all_features = set()
    for features in plan_featurization.VARIABLES.values():
        all_features.update(features)
    
    for feat_name in all_features:
        if feat_name == 'op_name':
            if actual_op_names:
                # å®Ÿéš›ã®ãƒ—ãƒ©ãƒ³ã‹ã‚‰åé›†ã—ãŸæ¼”ç®—å­ã‚’ä½¿ç”¨ã—ã€é€£ç¶šã—ãŸIDã‚’å‰²ã‚Šå½“ã¦ã‚‹
                sorted_ops = sorted(actual_op_names)
                operator_dict = {op: idx for idx, op in enumerate(sorted_ops)}
                print(f"  - op_name: {len(sorted_ops)}å€‹ã®æ¼”ç®—å­ã‚’é€£ç¶šIDã§å‰²ã‚Šå½“ã¦")
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å…ƒã®ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ï¼‰
                operator_dict = {
                    'Aggregate': 0, 'LocalExchange': 1, 'RemoteSource': 2,
                    'ScanFilter': 3, 'ScanFilterProject': 4, 'Project': 5,
                    'InnerJoin': 6, 'HashJoin': 7, 'NestedLoopJoin': 8,
                    'Sort': 87, 'Limit': 95, 'TopN': 11,
                    'TableScan': 13, 'FilterProject': 14, 'Exchange': 15,
                    'LeftJoin': 32, 'ScanProject': 60, 'Filter': 61,
                    'CrossJoin': 96,  # å®Ÿéš›ã«ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ãŒãƒãƒƒãƒ”ãƒ³ã‚°ã«ãªã„æ¼”ç®—å­ã‚’è¿½åŠ 
                }
                max_operator_id = max(operator_dict.values()) + 1
            
            if actual_op_names:
                # é€£ç¶šIDã®å ´åˆã€no_valsã¯æ¼”ç®—å­æ•°ã«ä½™è£•ã‚’æŒãŸã›ã‚‹
                # å®Ÿéš›ã®æ¼”ç®—å­æ•°ã«å¯¾ã—ã¦ååˆ†ãªä½™è£•ã‚’æŒãŸã›ã‚‹ï¼ˆå°†æ¥ã®æ‹¡å¼µã«ã‚‚å¯¾å¿œï¼‰
                no_vals = max(200, len(operator_dict) * 2)  # 2å€ã®ä½™è£•ã‚’æŒãŸã›ã‚‹
            else:
                # ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸIDã®å ´åˆã€æœ€å¤§ID+1ã‚’ä½¿ç”¨
                max_operator_id = max(operator_dict.values()) + 1
                no_vals = max(200, max_operator_id * 2)  # 2å€ã®ä½™è£•ã‚’æŒãŸã›ã‚‹
            
            feature_statistics[feat_name] = {
                'type': str(FeatureType.categorical),
                'value_dict': operator_dict,
                'no_vals': no_vals
            }
        elif feat_name == 'operator':
            if filter_operators:
                # å®Ÿéš›ã®ãƒ—ãƒ©ãƒ³ã‹ã‚‰åé›†ã—ãŸãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¼”ç®—å­ã‚’ä½¿ç”¨ã—ã€é€£ç¶šã—ãŸIDã‚’å‰²ã‚Šå½“ã¦ã‚‹
                sorted_ops = sorted(filter_operators)
                operator_dict = {op: idx for idx, op in enumerate(sorted_ops)}
                print(f"  - operator: {len(sorted_ops)}å€‹ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¼”ç®—å­ã‚’é€£ç¶šIDã§å‰²ã‚Šå½“ã¦")
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å…ƒã®ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒãƒƒãƒ”ãƒ³ã‚°
                operator_dict = {
                    'Aggregate': 0, 'LocalExchange': 1, 'RemoteSource': 2,
                    'ScanFilter': 3, 'ScanFilterProject': 4, 'Project': 5,
                    'InnerJoin': 6, 'HashJoin': 7, 'NestedLoopJoin': 8,
                    'Sort': 87, 'Limit': 95, 'TopN': 11,
                    'TableScan': 13, 'FilterProject': 14, 'Exchange': 15,
                    'LeftJoin': 32, 'ScanProject': 60, 'Filter': 61,
                    'CrossJoin': 96,
                }
            
            if filter_operators:
                # é€£ç¶šIDã®å ´åˆã€ä½™è£•ã‚’æŒãŸã›ã‚‹
                max_operator_id = len(operator_dict)
                no_vals = max(200, max_operator_id * 2)  # 2å€ã®ä½™è£•ã‚’æŒãŸã›ã‚‹
            else:
                # ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸIDã®å ´åˆ
                max_operator_id = max(operator_dict.values()) + 1
                no_vals = max(200, max_operator_id * 2)  # 2å€ã®ä½™è£•ã‚’æŒãŸã›ã‚‹
            
            feature_statistics[feat_name] = {
                'type': str(FeatureType.categorical),
                'value_dict': operator_dict,
                'no_vals': no_vals
            }
        elif feat_name == 'aggregation':
            # é›†ç´„é–¢æ•°ã®ç‰¹å¾´é‡çµ±è¨ˆ
            aggregation_dict = {
                'Aggregator.COUNT': 0,
                'Aggregator.SUM': 1,
                'Aggregator.AVG': 2,
                'Aggregator.MIN': 3,
                'Aggregator.MAX': 4,
                None: 5  # é›†ç´„ãªã—
            }
            feature_statistics[feat_name] = {
                'type': str(FeatureType.categorical),
                'value_dict': aggregation_dict,
                'no_vals': len(aggregation_dict)
            }
        elif feat_name in ['table_name', 'column_name']:
            feature_statistics[feat_name] = {
                'type': str(FeatureType.categorical),
                'value_dict': {},
                'no_vals': 1000
            }
        elif feat_name in ['rows', 'size', 'cpu', 'memory', 'network']:
            feature_statistics[feat_name] = {
                'type': str(FeatureType.numeric),
                'mean': 0.0,
                'std': 1.0,
                'min': 0.0,
                'max': 1000000.0,
                'center': 0.0,
                'scale': 1.0
            }
        else:
            # ãã®ä»–ã®ç‰¹å¾´é‡ã¯æ•°å€¤ã¨ã—ã¦æ‰±ã†
            feature_statistics[feat_name] = {
                'type': str(FeatureType.numeric),
                'mean': 0.0,
                'std': 1.0,
                'min': 0.0,
                'max': 100.0,
                'center': 0.0,
                'scale': 1.0
            }
    
    return feature_statistics


def collect_feature_statistics(workload_run_paths, output_path):
    """
    Trinoãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã‹ã‚‰ç‰¹å¾´é‡çµ±è¨ˆã‚’åé›†
    
    Args:
        workload_run_paths: ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œçµæœã®ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆ
        output_path: çµ±è¨ˆæƒ…å ±ã®å‡ºåŠ›ãƒ‘ã‚¹
    """
    print(f"ğŸ“Š ç‰¹å¾´é‡çµ±è¨ˆæƒ…å ±ã‚’åé›†ä¸­...")
    
    # gather_feature_statisticsé–¢æ•°ã‚’ä½¿ç”¨
    gather_feature_statistics(workload_run_paths, output_path)
    
    print(f"âœ… ç‰¹å¾´é‡çµ±è¨ˆæƒ…å ±ã‚’ {output_path} ã«ä¿å­˜ã—ã¾ã—ãŸ")


def train_epoch(model, train_loader, optimizer, device):
    """1ã‚¨ãƒãƒƒã‚¯ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°"""
    model.train()
    total_loss = 0
    num_batches = 0
    
    for graph, features, labels, sample_idxs in tqdm(train_loader, desc="Training"):
        # ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‡ãƒã‚¤ã‚¹ã«è»¢é€
        graph = graph.to(device)
        features = {k: v.to(device) for k, v in features.items()}
        labels_tensor = torch.tensor(labels, dtype=torch.float32, device=device).reshape(-1, 1)
        
        optimizer.zero_grad()
        
        # ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹
        predictions = model((graph, features))
        
        # æå¤±è¨ˆç®—
        loss = model.loss_fxn(predictions, labels_tensor)
        
        # ãƒãƒƒã‚¯ãƒ—ãƒ­ãƒ‘ã‚²ãƒ¼ã‚·ãƒ§ãƒ³
        loss.backward()
        
        # å‹¾é…ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°
        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
        
        optimizer.step()
        
        total_loss += loss.item()
        num_batches += 1
    
    avg_loss = total_loss / num_batches if num_batches > 0 else 0
    return avg_loss


def validate(model, val_loader, device):
    """æ¤œè¨¼"""
    model.eval()
    total_loss = 0
    num_batches = 0
    predictions_all = []
    labels_all = []
    
    with torch.no_grad():
        for graph, features, labels, sample_idxs in tqdm(val_loader, desc="Validation"):
            # ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‡ãƒã‚¤ã‚¹ã«è»¢é€
            graph = graph.to(device)
            features = {k: v.to(device) for k, v in features.items()}
            labels_tensor = torch.tensor(labels, dtype=torch.float32, device=device).reshape(-1, 1)
            
            # ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹
            predictions = model((graph, features))
            
            # æå¤±è¨ˆç®—
            loss = model.loss_fxn(predictions, labels_tensor)
            total_loss += loss.item()
            num_batches += 1
            
            predictions_all.append(predictions.cpu().numpy())
            labels_all.append(labels_tensor.cpu().numpy())
    
    avg_loss = total_loss / num_batches if num_batches > 0 else 0
    
    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
    if len(predictions_all) > 0:
        predictions_all = np.concatenate(predictions_all).flatten()
        labels_all = np.concatenate(labels_all).flatten()
        
        # ã‚¼ãƒ­é™¤ç®—ã‚’é˜²ããŸã‚ã«å°ã•ãªå€¤ã§ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°
        epsilon = 1e-6
        safe_predictions = np.clip(predictions_all, epsilon, None)
        safe_labels = np.clip(labels_all, epsilon, None)
        
        # Q-Error (metrics.pyã®å®Ÿè£…ã‚’ä½¿ç”¨)
        median_q_error = QError(percentile=50).evaluate_metric(labels=safe_labels, preds=safe_predictions)
        q_errors = np.maximum(safe_predictions / safe_labels, safe_labels / safe_predictions)
        mean_q_error = float(np.mean(q_errors))
        
        # RMSE (metrics.pyã®å®Ÿè£…ã‚’ä½¿ç”¨)
        rmse = RMSE().evaluate_metric(labels=labels_all, preds=predictions_all)
        
        return avg_loss, median_q_error, mean_q_error, rmse
    
    return avg_loss, None, None, None


def build_parser() -> argparse.ArgumentParser:
    """Build the argument parser for Zero-Shot training."""
    parser = argparse.ArgumentParser(description='Train Trino Zero-Shot Model (çµ±åˆç‰ˆ)')
    
    # ãƒ¢ãƒ¼ãƒ‰é¸æŠ
    parser.add_argument(
        '--mode',
        type=str,
        choices=['train', 'train_multi_all'],
        default='train',
        help='Training mode: train (single dataset) or train_multi_all (leave-one-out across all datasets)'
    )
    
    # ãƒ‡ãƒ¼ã‚¿é–¢é€£ã®å¼•æ•°
    parser.add_argument('--train_files', type=str, required=False,
                        help='ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã€trainãƒ¢ãƒ¼ãƒ‰ã§å¿…é ˆï¼‰')
    parser.add_argument('--test_file', type=str, required=False,
                        help='ãƒ†ã‚¹ãƒˆç”¨ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆtrainãƒ¢ãƒ¼ãƒ‰ã§å¿…é ˆï¼‰')
    parser.add_argument('--statistics_file', type=str, default=None,
                        help='ç‰¹å¾´é‡çµ±è¨ˆæƒ…å ±ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰')
    parser.add_argument('--statistics_dir', type=str, default=None,
                        help='ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±è¨ˆæƒ…å ±ã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆæŒ‡å®šæ™‚ã®ã¿çµ±è¨ˆæƒ…å ±ã‚’ä½¿ç”¨ï¼‰')
    parser.add_argument('--catalog', type=str, default=None,
                        help='Trinoã‚«ã‚¿ãƒ­ã‚°åï¼ˆçµ±è¨ˆæƒ…å ±ä½¿ç”¨æ™‚ã«å¿…è¦ï¼‰')
    parser.add_argument('--schema', type=str, default=None,
                        help='ã‚¹ã‚­ãƒ¼ãƒåï¼ˆçµ±è¨ˆæƒ…å ±ä½¿ç”¨æ™‚ã«å¿…è¦ï¼‰')
    
    # ãƒ¢ãƒ‡ãƒ«é–¢é€£ã®å¼•æ•°
    parser.add_argument('--output_dir', type=str, default='models/trino_zeroshot',
                        help='ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    parser.add_argument('--epochs', type=int, default=100,
                        help='ã‚¨ãƒãƒƒã‚¯æ•°')
    parser.add_argument('--batch_size', type=int, default=32,
                        help='ãƒãƒƒãƒã‚µã‚¤ã‚º')
    parser.add_argument('--lr', type=float, default=0.001,
                        help='å­¦ç¿’ç‡')
    parser.add_argument('--hidden_dim', type=int, default=128,
                        help='éš ã‚Œå±¤ã®æ¬¡å…ƒæ•°')
    parser.add_argument('--device', type=str, default='cuda' if torch.cuda.is_available() else 'cpu',
                        help='ãƒ‡ãƒã‚¤ã‚¹ (cuda/cpu)')
    
    # ãƒ‡ãƒ¼ã‚¿å‡¦ç†é–¢é€£ã®å¼•æ•°
    parser.add_argument('--max_plans_per_file', type=int, default=None,
                        help='å„ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€æœ€å¤§ãƒ—ãƒ©ãƒ³æ•°')
    parser.add_argument('--val_ratio', type=float, default=0.15,
                        help='æ¤œè¨¼ã‚»ãƒƒãƒˆã®å‰²åˆ')
    parser.add_argument('--num_workers', type=int, default=0,
                        help='DataLoaderã®ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°')
    parser.add_argument(
        '--plans_dir',
        type=str,
        default='/Users/an/query_engine/explain_analyze_results/',
        help='Directory containing .txt plan files for multiple datasets (required for train_multi_all mode)'
    )
    
    return parser


def run(args) -> int:
    """Run Zero-Shot training with parsed arguments."""
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print("=" * 80)
    print("Trino Zero-Shot Model Training (çµ±åˆç‰ˆ)")
    print(f"Mode: {args.mode}")
    if 'ZERO_SHOT_DATASETS_DIR' in os.environ:
        print(f"ZERO_SHOT_DATASETS_DIR: {os.environ['ZERO_SHOT_DATASETS_DIR']}")
    print("=" * 80)
    
    # train_multi_allãƒ¢ãƒ¼ãƒ‰ã®å‡¦ç†
    if args.mode == 'train_multi_all':
        return run_train_multi_all(args, output_dir)
    
    # å¾“æ¥ã®trainãƒ¢ãƒ¼ãƒ‰
    if not args.train_files or not args.test_file:
        raise ValueError("--train_files and --test_file are required for train mode")
    
    print(f"Train files: {args.train_files}")
    print(f"Test file: {args.test_file}")
    print(f"Output directory: {args.output_dir}")
    print()
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±è¨ˆæƒ…å ±ã®æº–å‚™ï¼ˆãƒ—ãƒ©ãƒ³ã‹ã‚‰æŠ½å‡ºã‚’å„ªå…ˆï¼‰
    db_statistics = {}
    print(f"Epochs: {args.epochs}")
    print(f"Batch size: {args.batch_size}")
    print(f"Learning rate: {args.lr}")
    print(f"Device: {args.device}")
    print()
    
    # 1. ãƒ—ãƒ©ãƒ³ã®èª­ã¿è¾¼ã¿
    print("ğŸ“‚ ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ—ãƒ©ãƒ³ã®èª­ã¿è¾¼ã¿")
    train_file_paths = [Path(p.strip()) for p in args.train_files.split(',')]
    test_file_path = Path(args.test_file)
    
    # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ—ãƒ©ãƒ³ã®èª­ã¿è¾¼ã¿
    train_plans = load_plans_from_files(train_file_paths, args.max_plans_per_file)
    
    # ãƒ†ã‚¹ãƒˆãƒ—ãƒ©ãƒ³ã®èª­ã¿è¾¼ã¿
    test_plans = load_plans_from_files([test_file_path], args.max_plans_per_file)
    
    print()
    
    # 1.5. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±è¨ˆæƒ…å ±ã®æº–å‚™ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ - ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰
    # æ³¨æ„: çµ±è¨ˆæƒ…å ±ã¯æ—¢ã«plan_parametersã«å«ã¾ã‚Œã¦ã„ã‚‹ãŸã‚ã€é€šå¸¸ã¯å¤–éƒ¨çµ±è¨ˆãƒ•ã‚¡ã‚¤ãƒ«ã¯ä¸è¦
    # ãŸã ã—ã€äº’æ›æ€§ã®ãŸã‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¨ã—ã¦æ®‹ã™
    db_statistics = {}
    if args.catalog and args.schema and args.statistics_dir:
        stats_dir_path = Path(args.statistics_dir) / f"{args.catalog}_{args.schema}"
        if stats_dir_path.exists():
            try:
                loaded_stats = load_database_statistics(
                    catalog=args.catalog,
                    schema=args.schema,
                    stats_dir=args.statistics_dir,
                    prefer_zero_shot=True
                )
                
                from types import SimpleNamespace
                for file_idx, file_path in enumerate([Path(p.strip()) for p in args.train_files.split(',')] + [Path(args.test_file)]):
                    db_stats = SimpleNamespace(
                        table_stats=loaded_stats.get('table_stats', {}),
                        column_stats=loaded_stats.get('column_stats', {})
                    )
                    db_statistics[file_idx] = db_stats
                
                has_stats = (
                    loaded_stats.get('table_stats') or 
                    loaded_stats.get('column_stats')
                )
                
                if has_stats:
                    print(f"â„¹ï¸  å¤–éƒ¨çµ±è¨ˆæƒ…å ±ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰")
                    print(f"   - ãƒ†ãƒ¼ãƒ–ãƒ«çµ±è¨ˆ: {len(loaded_stats.get('table_stats', {}))} ãƒ†ãƒ¼ãƒ–ãƒ«")
                    print(f"   - ã‚«ãƒ©ãƒ çµ±è¨ˆ: {len(loaded_stats.get('column_stats', {}))} ã‚«ãƒ©ãƒ ")
                    print(f"   æ³¨æ„: çµ±è¨ˆæƒ…å ±ã¯æ—¢ã«plan_parametersã«å«ã¾ã‚Œã¦ã„ã‚‹ãŸã‚ã€å¤–éƒ¨çµ±è¨ˆã¯è£œå®Œç”¨é€”ã§ã™")
            except Exception as e:
                print(f"âš ï¸  å¤–éƒ¨çµ±è¨ˆæƒ…å ±ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ï¼ˆplan_parametersã‹ã‚‰çµ±è¨ˆæƒ…å ±ã‚’ä½¿ç”¨ï¼‰: {e}")
    
    if not db_statistics:
        print(f"â„¹ï¸  çµ±è¨ˆæƒ…å ±ã¯plan_parametersã‹ã‚‰è‡ªå‹•çš„ã«å–å¾—ã•ã‚Œã¾ã™")
    print()
    
    # 2. ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°/æ¤œè¨¼ã‚»ãƒƒãƒˆã®åˆ†å‰²
    print("ğŸ“Š ã‚¹ãƒ†ãƒƒãƒ—2: ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°/æ¤œè¨¼ã‚»ãƒƒãƒˆã®åˆ†å‰²")
    val_size = int(len(train_plans) * args.val_ratio)
    # æ¤œè¨¼ã‚»ãƒƒãƒˆãŒç©ºã«ãªã‚‰ãªã„ã‚ˆã†ã«ã€å°‘ãªãã¨ã‚‚1å€‹ã¯ç¢ºä¿ï¼ˆãŸã ã—ã€train_plansãŒ1å€‹ã®å ´åˆã¯é™¤ãï¼‰
    if val_size == 0 and len(train_plans) > 1:
        val_size = 1
    train_size = len(train_plans) - val_size
    
    train_plans_split, val_plans_split = random_split(
        train_plans, 
        [train_size, val_size],
        generator=torch.Generator().manual_seed(42)
    )
    
    print(f"  - ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ—ãƒ©ãƒ³: {len(train_plans_split)}")
    print(f"  - æ¤œè¨¼ãƒ—ãƒ©ãƒ³: {len(val_plans_split)}")
    print(f"  - ãƒ†ã‚¹ãƒˆãƒ—ãƒ©ãƒ³: {len(test_plans)}")
    print()
    
    # 3. ç‰¹å¾´é‡çµ±è¨ˆã®æº–å‚™
    print("ğŸ”§ ã‚¹ãƒ†ãƒƒãƒ—3: ç‰¹å¾´é‡çµ±è¨ˆã®æº–å‚™")
    plan_featurization = TrinoTrueCardDetail()
    
    # ç‰¹å¾´é‡çµ±è¨ˆæƒ…å ±ã®èª­ã¿è¾¼ã¿ã¾ãŸã¯ä½œæˆ
    if args.statistics_file and Path(args.statistics_file).exists():
        with open(args.statistics_file, 'r') as f:
            feature_statistics = json.load(f)
        print(f"  - æ—¢å­˜ã®çµ±è¨ˆæƒ…å ±ã‚’èª­ã¿è¾¼ã¿: {len(feature_statistics)} features")
    else:
        # ã€é‡è¦ã€‘å…¨ãƒ—ãƒ©ãƒ³ï¼ˆtrain + val + testï¼‰ã‹ã‚‰ç‰¹å¾´é‡çµ±è¨ˆã‚’åé›†
        # embeddingãƒ†ãƒ¼ãƒ–ãƒ«ã¯ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–æ™‚ã«å›ºå®šã•ã‚Œã‚‹ãŸã‚ã€äº‹å‰ã«ã™ã¹ã¦ã®æ¼”ç®—å­ã‚’åé›†ã™ã‚‹å¿…è¦ãŒã‚ã‚‹
        all_plans_for_stats = train_plans + test_plans
        print(f"  - çµ±è¨ˆåé›†å¯¾è±¡: {len(all_plans_for_stats)}å€‹ã®ãƒ—ãƒ©ãƒ³ï¼ˆtrain + testï¼‰")
        feature_statistics = create_feature_statistics_from_plans(
            all_plans_for_stats,
            plan_featurization,
            args.statistics_file
        )
    
    # db_statisticsãŒNoneã®å ´åˆã¯ç©ºã®è¾æ›¸ã‚’ä½¿ç”¨ï¼ˆå¾Œæ–¹äº’æ›æ€§ï¼‰
    if db_statistics is None:
        db_statistics = {}
    
    print()
    
    # 4. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨DataLoaderã®ä½œæˆ
    print("ğŸ“¦ ã‚¹ãƒ†ãƒƒãƒ—4: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨DataLoaderã®ä½œæˆ")
    
    # collate_fnã‚’ä½œæˆï¼ˆãƒãƒƒãƒã‚’ã‚°ãƒ©ãƒ•ã«å¤‰æ›ï¼‰
    collate_fn = functools.partial(
        trino_plan_collator,
        feature_statistics=feature_statistics,
        db_statistics=db_statistics,
        plan_featurization=plan_featurization
    )
    
    # DataLoaderã®ä½œæˆ
    train_loader = DataLoader(
        TrinoPlanDataset([train_plans[i] for i in train_plans_split.indices]),
        batch_size=args.batch_size,
        shuffle=True,
        num_workers=args.num_workers,
        collate_fn=collate_fn
    )
    
    val_loader = DataLoader(
        TrinoPlanDataset([train_plans[i] for i in val_plans_split.indices]),
        batch_size=args.batch_size,
        shuffle=False,
        num_workers=args.num_workers,
        collate_fn=collate_fn
    )
    
    test_loader = DataLoader(
        TrinoPlanDataset(test_plans),
        batch_size=args.batch_size,
        shuffle=False,
        num_workers=args.num_workers,
        collate_fn=collate_fn
    )
    
    print(f"  - ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒãƒƒãƒæ•°: {len(train_loader)}")
    print(f"  - æ¤œè¨¼ãƒãƒƒãƒæ•°: {len(val_loader)}")
    print(f"  - ãƒ†ã‚¹ãƒˆãƒãƒƒãƒæ•°: {len(test_loader)}")
    print()
    
    # 5. ãƒ¢ãƒ‡ãƒ«ä½œæˆ
    print("ğŸ¤– ã‚¹ãƒ†ãƒƒãƒ—5: ãƒ¢ãƒ‡ãƒ«ä½œæˆ")
    model_config = ZeroShotModelConfig(
        hidden_dim=args.hidden_dim,
        hidden_dim_plan=args.hidden_dim,
        hidden_dim_pred=args.hidden_dim,
        p_dropout=0.1,
        featurization=plan_featurization,
        output_dim=1,
        batch_size=args.batch_size
    )
    
    # Trinoå›ºæœ‰ã®è¨­å®š
    # encoders: å„ãƒãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—ã®ç‰¹å¾´é‡ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
    encoders = [
        ('column', plan_featurization.COLUMN_FEATURES),
        ('table', plan_featurization.TABLE_FEATURES),
        ('output_column', plan_featurization.OUTPUT_COLUMN_FEATURES),
        ('filter_column', plan_featurization.FILTER_FEATURES + plan_featurization.COLUMN_FEATURES),
        ('plan', plan_featurization.PLAN_FEATURES),
        ('logical_pred', plan_featurization.FILTER_FEATURES),
    ]
    
    # prepasses: Trinoå›ºæœ‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ‘ãƒƒã‚·ãƒ³ã‚°ï¼ˆcolumnã‹ã‚‰output_columnã¸ï¼‰
    # allow_emptyã¯message_passingå†…ã§allow_empty_edgesã‹ã‚‰è‡ªå‹•çš„ã«è¨­å®šã•ã‚Œã‚‹ãŸã‚ã€ã“ã“ã§ã¯æŒ‡å®šã—ãªã„
    prepasses = [dict(model_name='column_output_column', e_name='col_output_col')]
    tree_model_types = ['column_output_column']
    
    # ZeroShotModelã‚’ç›´æ¥ä½¿ç”¨ï¼ˆallow_empty_edges=Trueã§Trinoå¯¾å¿œï¼‰
    model = ZeroShotModel(
        model_config=model_config,
        device=args.device,
        feature_statistics=feature_statistics,
        plan_featurization=plan_featurization,
        prepasses=prepasses,
        add_tree_model_types=tree_model_types,
        encoders=encoders,
        allow_empty_edges=True  # Trinoã§ã¯ã‚¨ãƒƒã‚¸ãŒå­˜åœ¨ã—ãªã„å ´åˆãŒã‚ã‚‹ãŸã‚
    )
    
    model = model.to(args.device)
    
    print(f"  - ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in model.parameters()):,}")
    print()
    
    # 6. ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã¨ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©
    print("âš™ï¸  ã‚¹ãƒ†ãƒƒãƒ—6: ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶è¨­å®š")
    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', factor=0.5, patience=10, verbose=True
    )
    print(f"  - Optimizer: Adam (lr={args.lr})")
    print(f"  - Scheduler: ReduceLROnPlateau")
    print()
    
    # 7. ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ«ãƒ¼ãƒ—
    print("ğŸš€ ã‚¹ãƒ†ãƒƒãƒ—7: ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°é–‹å§‹")
    best_val_loss = float('inf')
    best_epoch = 0
    
    for epoch in range(args.epochs):
        # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°
        train_loss = train_epoch(model, train_loader, optimizer, args.device)
        
        # æ¤œè¨¼
        val_result = validate(model, val_loader, args.device)
        val_loss, val_median_q_error, val_mean_q_error, val_rmse = val_result
        
        # å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©
        scheduler.step(val_loss)
        
        # ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            best_epoch = epoch + 1
            # ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜
            torch.save(model.state_dict(), output_dir / 'best_model.pt')
        
        # ãƒ­ã‚°å‡ºåŠ›
        if (epoch + 1) % 5 == 0 or epoch == 0:
            median_q = f"{val_median_q_error:.4f}" if val_median_q_error is not None else "N/A"
            mean_q = f"{val_mean_q_error:.4f}" if val_mean_q_error is not None else "N/A"
            rmse_val = f"{val_rmse:.4f}" if val_rmse is not None else "N/A"
            print(
                f"Epoch [{epoch+1}/{args.epochs}] "
                f"Train Loss: {train_loss:.4f}, "
                f"Val Loss: {val_loss:.4f}, "
                f"Val Median Q-Error: {median_q}, "
                f"Val Mean Q-Error: {mean_q}, "
                f"Val RMSE: {rmse_val}, "
                f"Best: {best_val_loss:.4f} (Epoch {best_epoch})"
            )
    
    print()
    print("âœ… ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†!")
    print()
    
    # 8. ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã§ã®è©•ä¾¡
    print("ğŸ“Š ã‚¹ãƒ†ãƒƒãƒ—8: ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã§ã®æœ€çµ‚è©•ä¾¡")
    
    # ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿
    model.load_state_dict(torch.load(output_dir / 'best_model.pt'))
    test_result = validate(model, test_loader, args.device)
    test_loss, test_median_q_error, test_mean_q_error, test_rmse = test_result
    
    print(f"ã€ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆè©•ä¾¡çµæœã€‘")
    print(f"  - ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(test_plans)}")
    print(f"  - Test Loss: {test_loss:.4f}")
    print(f"  - RMSE: {test_rmse:.4f}ç§’ ({test_rmse*1000:.2f}ms)")
    print(f"  - Median Q-Error: {test_median_q_error:.4f}")
    print(f"  - Mean Q-Error: {test_mean_q_error:.4f}")
    print()
    
    print("=" * 80)
    print("ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†ï¼")
    print(f"Best Validation Loss: {best_val_loss:.4f} (Epoch {best_epoch})")
    print(f"Test Median Q-Error: {test_median_q_error:.4f}")
    print(f"Model saved to: {output_dir / 'best_model.pt'}")
    print("=" * 80)
    
    return 0


def load_all_datasets_once(plans_dir: Path, available_datasets: list, max_plans_per_file=None):
    """
    Parse all datasets' .txt plans under plans_dir once.
    This is more efficient than parsing for each leave-one-out iteration.
    
    Returns: dict {dataset_name: [list of plans]}
    """
    def infer_dataset_name(p: Path, ALL_DATASETS: list) -> str:
        stem = p.stem
        parts = stem.split('_')
        matched_dataset = None
        for i in range(len(parts), 0, -1):
            candidate = '_'.join(parts[:i])
            if candidate in ALL_DATASETS:
                matched_dataset = candidate
                break
        if matched_dataset:
            return matched_dataset
        return stem.split('_')[0]
    
    ALL_DATASETS = [
        'accidents', 'airline', 'baseball', 'basketball', 'carcinogenesis',
        'consumer', 'credit', 'employee', 'fhnk', 'financial', 'geneea',
        'genome', 'hepatitis', 'imdb', 'movielens', 'seznam', 'ssb',
        'tournament', 'tpc_h', 'walmart'
    ]
    
    txt_files = sorted([p for p in plans_dir.glob('*.txt')])
    dataset_to_files = {}
    for p in txt_files:
        ds = infer_dataset_name(p, ALL_DATASETS)
        if ds in available_datasets:
            dataset_to_files.setdefault(ds, []).append(p)
    
    all_plans_by_dataset = {}
    print("=" * 80)
    print("ã‚¹ãƒ†ãƒƒãƒ—0: å…¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ—ãƒ©ãƒ³ã‚’èª­ã¿è¾¼ã¿ä¸­...")
    print("=" * 80)
    print()
    
    for ds in available_datasets:
        if ds in dataset_to_files:
            files = dataset_to_files[ds]
            print(f"  èª­ã¿è¾¼ã¿ä¸­: {ds} ({len(files)} ãƒ•ã‚¡ã‚¤ãƒ«)...")
            plans = load_plans_from_files(files, max_plans_per_file)
            all_plans_by_dataset[ds] = plans
            print(f"    âœ… {ds}: {len(plans)} ãƒ—ãƒ©ãƒ³")
    
    print(f"\nâœ… å…¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èª­ã¿è¾¼ã¿å®Œäº†")
    print(f"  - èª­ã¿è¾¼ã‚“ã ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {len(all_plans_by_dataset)}")
    for ds, plans in all_plans_by_dataset.items():
        print(f"    - {ds}: {len(plans)} ãƒ—ãƒ©ãƒ³")
    print()
    
    return all_plans_by_dataset


def run_train_multi_all(args, output_dir: Path) -> int:
    """20å€‹ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã¤ã„ã¦leave-one-out validationã‚’å®Ÿè¡Œ"""
    # ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹20å€‹ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆé †ï¼‰
    ALL_DATASETS = [
        'accidents', 'airline', 'baseball', 'basketball', 'carcinogenesis',
        'consumer', 'credit', 'employee', 'fhnk', 'financial', 'geneea',
        'genome', 'hepatitis', 'imdb', 'movielens', 'seznam', 'ssb',
        'tournament', 'tpc_h', 'walmart'
    ]
    
    plans_dir = Path(args.plans_dir)
    
    # åˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç¢ºèª
    txt_files = sorted([p for p in plans_dir.glob('*.txt')])
    available_datasets = set()
    for p in txt_files:
        stem = p.stem  # .txtã‚’é™¤ã„ãŸãƒ•ã‚¡ã‚¤ãƒ«å
        parts = stem.split('_')
        # æœ€é•·ãƒãƒƒãƒ: ALL_DATASETSã‹ã‚‰æœ€é•·ã®ä¸€è‡´ã‚’æ¢ã™ï¼ˆtpc_hãªã©ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåã«å¯¾å¿œï¼‰
        matched_dataset = None
        for i in range(len(parts), 0, -1):
            candidate = '_'.join(parts[:i])
            if candidate in ALL_DATASETS:
                matched_dataset = candidate
                break
        if matched_dataset:
            available_datasets.add(matched_dataset)
    
    available_datasets = sorted(list(available_datasets))
    print(f"\n{'='*80}")
    print(f"Leave-One-Out Validation for All Datasets (Zero-Shot)")
    print(f"{'='*80}")
    print(f"åˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {len(available_datasets)} / {len(ALL_DATASETS)}")
    print(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {', '.join(available_datasets)}")
    print(f"å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {output_dir}")
    print(f"{'='*80}\n")
    
    # æœ€åˆã«1å›ã ã‘å…¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ—ãƒ©ãƒ³ã‚’èª­ã¿è¾¼ã‚€
    all_plans_by_dataset = load_all_datasets_once(
        plans_dir=plans_dir,
        available_datasets=available_datasets,
        max_plans_per_file=args.max_plans_per_file
    )
    
    # å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã¤ã„ã¦è¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
    results_summary = []
    plan_featurization = TrinoTrueCardDetail()
    
    for idx, test_dataset in enumerate(available_datasets, 1):
        print(f"\n{'#'*80}")
        print(f"# [{idx}/{len(available_datasets)}] Testing dataset: {test_dataset}")
        print(f"{'#'*80}\n")
        
        try:
            # æ—¢ã«èª­ã¿è¾¼ã‚“ã ãƒ—ãƒ©ãƒ³ã‹ã‚‰train/testã‚’åˆ†å‰²
            if test_dataset not in all_plans_by_dataset:
                print(f"âš ï¸  {test_dataset}: ãƒ—ãƒ©ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                results_summary.append({
                    'test_dataset': test_dataset,
                    'status': 'skipped',
                    'reason': 'missing plans'
                })
                continue
            
            train_plans = []
            test_plans = all_plans_by_dataset[test_dataset]
            
            for ds, plans in all_plans_by_dataset.items():
                if ds != test_dataset:
                    train_plans.extend(plans)
            
            if not train_plans or not test_plans:
                print(f"âš ï¸  {test_dataset}: è¨“ç·´ãƒ—ãƒ©ãƒ³ã¾ãŸã¯ãƒ†ã‚¹ãƒˆãƒ—ãƒ©ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                results_summary.append({
                    'test_dataset': test_dataset,
                    'status': 'skipped',
                    'reason': 'missing plans'
                })
                continue
            
            # ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            model_dir = output_dir / f'models_{test_dataset}'
            model_dir.mkdir(parents=True, exist_ok=True)
            
            print(f"ğŸ“Š Leave-One-Out Validation [{idx}/{len(available_datasets)}]:")
            print(f"  - Training datasets: {len(all_plans_by_dataset) - 1} datasets")
            print(f"  - Training plans: {len(train_plans)}")
            print(f"  - Test dataset: {test_dataset}")
            print(f"  - Test plans: {len(test_plans)}")
            print()
            
            # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°/æ¤œè¨¼ã‚»ãƒƒãƒˆã®åˆ†å‰²ï¼ˆ19å€‹ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’train/valã«åˆ†å‰²ï¼‰
            val_size = int(len(train_plans) * args.val_ratio)
            if val_size == 0 and len(train_plans) > 1:
                val_size = 1
            train_size = len(train_plans) - val_size
            
            train_plans_split, val_plans_split = random_split(
                train_plans,
                [train_size, val_size],
                generator=torch.Generator().manual_seed(42)
            )
            
            print(f"âœ… 19å€‹ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰ä½œæˆ:")
            print(f"  - Train plans: {len(train_plans_split)}")
            print(f"  - Val plans (from 19 datasets): {len(val_plans_split)}")
            print()
            
            # ç‰¹å¾´é‡çµ±è¨ˆã®æº–å‚™ï¼ˆå…¨ãƒ—ãƒ©ãƒ³ã‹ã‚‰ï¼‰
            all_plans_for_stats = train_plans + test_plans
            statistics_file = model_dir / 'feature_statistics.json' if args.statistics_file is None else Path(args.statistics_file)
            feature_statistics = create_feature_statistics_from_plans(
                all_plans_for_stats,
                plan_featurization,
                str(statistics_file) if statistics_file != model_dir / 'feature_statistics.json' else None
            )
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±è¨ˆæƒ…å ±ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ - ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰
            # æ³¨æ„: çµ±è¨ˆæƒ…å ±ã¯æ—¢ã«plan_parametersã«å«ã¾ã‚Œã¦ã„ã‚‹ãŸã‚ã€é€šå¸¸ã¯å¤–éƒ¨çµ±è¨ˆãƒ•ã‚¡ã‚¤ãƒ«ã¯ä¸è¦
            db_statistics = {}
            if args.statistics_dir:
                try:
                    loaded_stats = load_database_statistics(
                        catalog='iceberg',
                        schema=test_dataset,
                        stats_dir=args.statistics_dir,
                        prefer_zero_shot=True
                    )
                    from types import SimpleNamespace
                    db_stats = SimpleNamespace(
                        table_stats=loaded_stats.get('table_stats', {}),
                        column_stats=loaded_stats.get('column_stats', {})
                    )
                    db_statistics[0] = db_stats
                    print(f"â„¹ï¸  å¤–éƒ¨çµ±è¨ˆæƒ…å ±ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰")
                except Exception as e:
                    print(f"âš ï¸  å¤–éƒ¨çµ±è¨ˆæƒ…å ±ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ï¼ˆplan_parametersã‹ã‚‰çµ±è¨ˆæƒ…å ±ã‚’ä½¿ç”¨ï¼‰: {e}")
            
            # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨DataLoaderã®ä½œæˆ
            collate_fn = functools.partial(
                trino_plan_collator,
                feature_statistics=feature_statistics,
                db_statistics=db_statistics,
                plan_featurization=plan_featurization
            )
            
            train_loader = DataLoader(
                TrinoPlanDataset([train_plans[i] for i in train_plans_split.indices]),
                batch_size=args.batch_size,
                shuffle=True,
                num_workers=args.num_workers,
                collate_fn=collate_fn
            )
            
            val_loader = DataLoader(
                TrinoPlanDataset([train_plans[i] for i in val_plans_split.indices]),
                batch_size=args.batch_size,
                shuffle=False,
                num_workers=args.num_workers,
                collate_fn=collate_fn
            )
            
            test_loader = DataLoader(
                TrinoPlanDataset(test_plans),
                batch_size=args.batch_size,
                shuffle=False,
                num_workers=args.num_workers,
                collate_fn=collate_fn
            )
            
            # ãƒ¢ãƒ‡ãƒ«ä½œæˆ
            model_config = ZeroShotModelConfig(
                hidden_dim=args.hidden_dim,
                hidden_dim_plan=args.hidden_dim,
                hidden_dim_pred=args.hidden_dim,
                p_dropout=0.1,
                featurization=plan_featurization,
                output_dim=1,
                batch_size=args.batch_size
            )
            
            encoders = [
                ('column', plan_featurization.COLUMN_FEATURES),
                ('table', plan_featurization.TABLE_FEATURES),
                ('output_column', plan_featurization.OUTPUT_COLUMN_FEATURES),
                ('filter_column', plan_featurization.FILTER_FEATURES + plan_featurization.COLUMN_FEATURES),
                ('plan', plan_featurization.PLAN_FEATURES),
                ('logical_pred', plan_featurization.FILTER_FEATURES),
            ]
            prepasses = [dict(model_name='column_output_column', e_name='col_output_col')]
            tree_model_types = ['column_output_column']
            
            model = ZeroShotModel(
                model_config=model_config,
                device=args.device,
                feature_statistics=feature_statistics,
                plan_featurization=plan_featurization,
                prepasses=prepasses,
                add_tree_model_types=tree_model_types,
                encoders=encoders,
                allow_empty_edges=True
            )
            model = model.to(args.device)
            
            # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã¨ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©
            optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)
            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
                optimizer, mode='min', factor=0.5, patience=10, verbose=False
            )
            
            # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ«ãƒ¼ãƒ—
            best_val_loss = float('inf')
            best_epoch = 0
            
            for epoch in range(args.epochs):
                train_loss = train_epoch(model, train_loader, optimizer, args.device)
                val_result = validate(model, val_loader, args.device)
                val_loss, val_median_q_error, val_mean_q_error, val_rmse = val_result
                
                scheduler.step(val_loss)
                
                if val_loss < best_val_loss:
                    best_val_loss = val_loss
                    best_epoch = epoch + 1
                    torch.save(model.state_dict(), model_dir / 'best_model.pt')
                
                if (epoch + 1) % 5 == 0 or epoch == 0:
                    median_q = f"{val_median_q_error:.4f}" if val_median_q_error is not None else "N/A"
                    mean_q = f"{val_mean_q_error:.4f}" if val_mean_q_error is not None else "N/A"
                    print(f"Epoch [{epoch+1}/{args.epochs}] Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Median Q-Error: {median_q}, Val Mean Q-Error: {mean_q}")
            
            # ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã§ã®è©•ä¾¡
            model.load_state_dict(torch.load(model_dir / 'best_model.pt'))
            test_result = validate(model, test_loader, args.device)
            test_loss, test_median_q_error, test_mean_q_error, test_rmse = test_result
            
            # ãƒ†ã‚¹ãƒˆçµæœã‚’ä¿å­˜
            test_results = {
                'test_loss': float(test_loss),
                'test_median_q_error': float(test_median_q_error) if test_median_q_error is not None else None,
                'test_mean_q_error': float(test_mean_q_error) if test_mean_q_error is not None else None,
                'test_rmse': float(test_rmse) if test_rmse is not None else None,
                'test_samples': len(test_plans)
            }
            
            results_file = model_dir / 'test_results.json'
            with open(results_file, 'w') as f:
                json.dump(test_results, f, indent=2)
            
            results_summary.append({
                'test_dataset': test_dataset,
                'model_dir': str(model_dir),
                'best_val_loss': float(best_val_loss),
                'best_epoch': int(best_epoch),
                **test_results,
                'status': 'completed'
            })
            
            print(f"âœ… [{idx}/{len(available_datasets)}] {test_dataset} ã®è¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆå®Œäº†")
            print(f"   ãƒ¢ãƒ‡ãƒ«ä¿å­˜å…ˆ: {model_dir}")
            print()
            
        except Exception as e:
            print(f"âŒ [{idx}/{len(available_datasets)}] {test_dataset} ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ:")
            print(f"   {e}")
            import traceback
            traceback.print_exc()
            results_summary.append({
                'test_dataset': test_dataset,
                'status': 'failed',
                'error': str(e)
            })
            continue
    
    # å…¨ä½“ã®ã‚µãƒãƒªãƒ¼ã‚’ä¿å­˜
    summary_file = output_dir / 'leave_one_out_summary.json'
    with open(summary_file, 'w') as f:
        json.dump({
            'total_datasets': len(available_datasets),
            'completed': len([r for r in results_summary if r['status'] == 'completed']),
            'failed': len([r for r in results_summary if r['status'] == 'failed']),
            'skipped': len([r for r in results_summary if r.get('status') == 'skipped']),
            'results': results_summary
        }, f, indent=2)
    
    print("\n" + "=" * 80)
    print("ğŸ‰ å…¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®Leave-One-Out Validationå®Œäº†ï¼")
    print("=" * 80)
    print(f"å®Œäº†: {len([r for r in results_summary if r['status'] == 'completed'])}/{len(available_datasets)}")
    print(f"å¤±æ•—: {len([r for r in results_summary if r['status'] == 'failed'])}/{len(available_datasets)}")
    print(f"ã‚µãƒãƒªãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«: {summary_file}")
    print()
    
    return 0


def main(argv: Optional[Sequence[str]] = None) -> int:
    """Main entry point for Zero-Shot training."""
    parser = build_parser()
    args = parser.parse_args(argv)
    return run(args)


if __name__ == "__main__":
    import sys
    from typing import Optional, Sequence
    sys.exit(main())

