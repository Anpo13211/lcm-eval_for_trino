"""
Trino Flat-Vector Model Implementation

Trinoã‚¯ã‚¨ãƒªãƒ—ãƒ©ãƒ³ç”¨ã®Flat-Vectorãƒ¢ãƒ‡ãƒ«ã€‚
ã‚¯ã‚¨ãƒªãƒ—ãƒ©ãƒ³ã‚’å¹³å¦åŒ–ã—ã€æ¼”ç®—å­ã‚¿ã‚¤ãƒ—ã¨ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£ã‹ã‚‰ç‰¹å¾´é‡ã‚’æŠ½å‡ºã—ã¦ã€
LightGBMã§å®Ÿè¡Œæ™‚é–“ã‚’äºˆæ¸¬ã™ã‚‹ã€‚

ä¸»ãªæ©Ÿèƒ½:
- load_trino_plans_from_files: Trinoãƒ—ãƒ©ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ—ãƒ©ãƒ³ã‚’èª­ã¿è¾¼ã‚€
- collect_operator_types: æ¼”ç®—å­ã‚¿ã‚¤ãƒ—ã‚’åé›†ã—ã¦ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«å¤‰æ›
- extract_flat_features: ãƒ—ãƒ©ãƒ³ã‹ã‚‰ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã‚’æŠ½å‡º
- create_flat_vector_dataset: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆ
- train_flat_vector_model: ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°
- predict_flat_vector_model: ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬
"""

import re
from pathlib import Path
from typing import List, Dict, Tuple
import numpy as np
import lightgbm as lgb
from tqdm import tqdm

from cross_db_benchmark.benchmark_tools.trino.parse_plan import parse_trino_plans, trino_timing_regex


class MockQuery:
    """ãƒ¢ãƒƒã‚¯ã®Queryã‚¯ãƒ©ã‚¹ï¼ˆTrinoãƒ—ãƒ©ãƒ³ã®ãƒ‘ãƒ¼ã‚¹ç”¨ï¼‰"""
    
    def __init__(self, plan_text):
        self.plan_text = plan_text
        self.timeout = False
        self.analyze_plans = [plan_text]
        self.verbose_plan = plan_text.split('\n')
        
        # å®Ÿè¡Œæ™‚é–“ã‚’æŠ½å‡º
        execution_time = None
        timing_match = trino_timing_regex.search(plan_text)
        if timing_match:
            execution_time = float(timing_match.group(4))
            execution_unit = timing_match.group(5)
            if execution_unit == 's':
                execution_time *= 1000
        
        if execution_time is None:
            execution_time_match = re.search(r'Execution(?: Time)?: ([\d.]+)(ms|s)', plan_text)
            if execution_time_match:
                execution_time = float(execution_time_match.group(1))
                if execution_time_match.group(2) == 's':
                    execution_time *= 1000
        
        self.execution_time = execution_time if execution_time is not None else 1000.0


class MockRunStats:
    """ãƒ¢ãƒƒã‚¯ã®RunStatsã‚¯ãƒ©ã‚¹ï¼ˆTrinoãƒ—ãƒ©ãƒ³ã®ãƒ‘ãƒ¼ã‚¹ç”¨ï¼‰"""
    
    def __init__(self, plans_text):
        self.plans_text = plans_text
        self.query_list = [MockQuery(plan_text) for plan_text in plans_text]
        self.database_stats = {}
    
    def __iter__(self):
        for plan_text in self.plans_text:
            yield plan_text


def load_trino_plans_from_files(file_paths: List[Path], max_plans_per_file=None, verbose=True):
    """
    è¤‡æ•°ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰Trinoãƒ—ãƒ©ãƒ³ã‚’èª­ã¿è¾¼ã¿
    
    Args:
        file_paths: ãƒ—ãƒ©ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆ
        max_plans_per_file: å„ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€æœ€å¤§ãƒ—ãƒ©ãƒ³æ•°
        verbose: è©³ç´°ãƒ­ã‚°ã‚’å‡ºåŠ›ã™ã‚‹ã‹
    
    Returns:
        å…¨ãƒ—ãƒ©ãƒ³ã®ãƒªã‚¹ãƒˆ
    """
    all_plans = []
    
    if verbose:
        print(f"ğŸ“‚ {len(file_paths)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ—ãƒ©ãƒ³ã‚’èª­ã¿è¾¼ã¿ä¸­...")
    
    iterator = tqdm(file_paths, desc="ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿") if verbose else file_paths
    
    for file_idx, file_path in enumerate(iterator):
        with open(file_path, 'r') as f:
            content = f.read()
        
        # ã‚¯ã‚¨ãƒªãƒ—ãƒ©ãƒ³ã‚’åˆ†å‰²
        plans_text = []
        current_plan = []
        
        for line in content.split('\n'):
            if line.startswith('-- ') and 'stmt' in line and current_plan:
                plans_text.append('\n'.join(current_plan))
                current_plan = [line]
            else:
                current_plan.append(line)
        
        if current_plan:
            plans_text.append('\n'.join(current_plan))
        
        # æœ€å¤§ãƒ—ãƒ©ãƒ³æ•°ã‚’åˆ¶é™
        if max_plans_per_file:
            plans_text = plans_text[:max_plans_per_file]
        
        if verbose:
            print(f"  - {file_path}: {len(plans_text)}å€‹ã®ãƒ—ãƒ©ãƒ³ã‚’æ¤œå‡º")
        
        # MockRunStatsã‚’ä½œæˆã—ã¦ãƒ‘ãƒ¼ã‚¹
        mock_stats = MockRunStats(plans_text)
        
        parsed_runs, _ = parse_trino_plans(
            mock_stats,
            min_runtime=0,
            max_runtime=1000000,
            parse_baseline=False,
            include_zero_card=True
        )
        
        if verbose:
            print(f"  - ãƒ‘ãƒ¼ã‚¹çµæœ: {len(parsed_runs['parsed_plans'])}å€‹ã®ãƒ—ãƒ©ãƒ³")
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹IDã‚’è¨­å®š
        for plan in parsed_runs['parsed_plans']:
            plan.database_id = file_idx
        
        all_plans.extend(parsed_runs['parsed_plans'])
    
    if verbose:
        print(f"  - ç·ãƒ—ãƒ©ãƒ³æ•°: {len(all_plans)}")
    
    return all_plans


def collect_operator_types(plans) -> Dict[str, int]:
    """
    ãƒ—ãƒ©ãƒ³ã‹ã‚‰æ¼”ç®—å­ã‚¿ã‚¤ãƒ—ã‚’åé›†ã—ã¦ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«å¤‰æ›
    
    Args:
        plans: TrinoPlanOperatorã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ãƒªã‚¹ãƒˆ
    
    Returns:
        æ¼”ç®—å­å -> ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®è¾æ›¸
    """
    op_types = set()
    
    def extract_op_types(plan):
        op_name = getattr(plan.plan_parameters, 'op_name', None)
        if op_name:
            op_types.add(op_name)
        for child in plan.children:
            extract_op_types(child)
    
    for plan in plans:
        extract_op_types(plan)
    
    # ã‚½ãƒ¼ãƒˆã—ã¦å†ç¾æ€§ã‚’ç¢ºä¿
    sorted_ops = sorted(list(op_types))
    op_idx_dict = {op: idx for idx, op in enumerate(sorted_ops)}
    
    print(f"ğŸ“Š è¦‹ã¤ã‹ã£ãŸæ¼”ç®—å­ã‚¿ã‚¤ãƒ—: {len(op_idx_dict)} ç¨®é¡")
    for op_name, idx in sorted(op_idx_dict.items(), key=lambda x: x[1]):
        print(f"  - {idx:3d}: {op_name}")
    
    return op_idx_dict


def extract_flat_features(plan, op_idx_dict: Dict[str, int], use_act_card=True):
    """
    Flat-Vectorç‰¹å¾´é‡ã‚’æŠ½å‡º
    
    Args:
        plan: TrinoPlanOperatorã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        op_idx_dict: æ¼”ç®—å­å -> ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®è¾æ›¸
        use_act_card: True=å®Ÿéš›ã®ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£ã€False=æ¨å®šã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£
    
    Returns:
        ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ï¼ˆnumpyé…åˆ—ï¼‰
    """
    no_ops = len(op_idx_dict)
    
    # æ¼”ç®—å­ã®å‡ºç¾å›æ•°
    feature_num_vec = np.zeros(no_ops)
    # æ¼”ç®—å­ã”ã¨ã®è¡Œæ•°
    feature_row_vec = np.zeros(no_ops)
    
    def extract_features_recursive(p):
        op_name = getattr(p.plan_parameters, 'op_name', None)
        if not op_name:
            return
        
        if op_name not in op_idx_dict:
            # æœªçŸ¥ã®æ¼”ç®—å­ã‚¿ã‚¤ãƒ—ï¼ˆå­¦ç¿’æ™‚ã«è¦‹ãªã‹ã£ãŸæ¼”ç®—å­ï¼‰
            print(f"âš ï¸  è­¦å‘Š: æœªçŸ¥ã®æ¼”ç®—å­ã‚¿ã‚¤ãƒ— '{op_name}' ã‚’ã‚¹ã‚­ãƒƒãƒ—")
            return
        
        op_idx = op_idx_dict[op_name]
        feature_num_vec[op_idx] += 1
        
        # ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£ã®æŠ½å‡º
        if use_act_card:
            # å®Ÿéš›ã®ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£ã‚’ä½¿ç”¨ï¼ˆSimpleNamespaceå¯¾å¿œï¼‰
            card = getattr(p.plan_parameters, 'act_output_rows', None)
            if card is None:
                card = getattr(p.plan_parameters, 'act_card', None)
            if card is None:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å®Ÿéš›ã®ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£ãŒãªã„å ´åˆã¯æ¨å®šå€¤ã‚’ä½¿ç”¨
                card = getattr(p.plan_parameters, 'est_rows', 0)
        else:
            # æ¨å®šã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£ã‚’ä½¿ç”¨ï¼ˆSimpleNamespaceå¯¾å¿œï¼‰
            card = getattr(p.plan_parameters, 'est_rows', None)
            if card is None:
                card = getattr(p.plan_parameters, 'est_card', 0)
        
        feature_row_vec[op_idx] += card
        
        # å­ãƒãƒ¼ãƒ‰ã‚’å†å¸°çš„ã«å‡¦ç†
        for child in p.children:
            extract_features_recursive(child)
    
    extract_features_recursive(plan)
    
    # ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã‚’é€£çµ
    feature_vec = np.concatenate((feature_num_vec, feature_row_vec))
    
    return feature_vec


def create_flat_vector_dataset(plans, op_idx_dict: Dict[str, int], use_act_card=True, verbose=True) -> Tuple[np.ndarray, np.ndarray]:
    """
    ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆ
    
    Args:
        plans: TrinoPlanOperatorã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ãƒªã‚¹ãƒˆ
        op_idx_dict: æ¼”ç®—å­å -> ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®è¾æ›¸
        use_act_card: True=å®Ÿéš›ã®ã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£ã€False=æ¨å®šã‚«ãƒ¼ãƒ‡ã‚£ãƒŠãƒªãƒ†ã‚£
        verbose: è©³ç´°ãƒ­ã‚°ã‚’å‡ºåŠ›ã™ã‚‹ã‹
    
    Returns:
        (ç‰¹å¾´è¡Œåˆ—, ãƒ©ãƒ™ãƒ«é…åˆ—)
    """
    feature_vecs = []
    labels = []
    
    iterator = tqdm(plans, desc="ç‰¹å¾´é‡æŠ½å‡º") if verbose else plans
    
    for plan in iterator:
        feature_vec = extract_flat_features(plan, op_idx_dict, use_act_card)
        feature_vecs.append(feature_vec)
        
        # ãƒ©ãƒ™ãƒ«ã¯å®Ÿè¡Œæ™‚é–“ï¼ˆç§’å˜ä½ï¼‰
        runtime_ms = plan.plan_runtime
        runtime_s = runtime_ms / 1000.0
        labels.append(runtime_s)
    
    X = np.array(feature_vecs)
    y = np.array(labels)
    
    return X, y


def train_flat_vector_model(
    X_train: np.ndarray,
    y_train: np.ndarray,
    X_val: np.ndarray,
    y_val: np.ndarray,
    num_boost_round: int = 1000,
    early_stopping_rounds: int = 20,
    seed: int = 42,
    verbose: bool = True
) -> lgb.Booster:
    """
    Flat-Vectorãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°
    
    Args:
        X_train: ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ç‰¹å¾´é‡
        y_train: ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ©ãƒ™ãƒ«
        X_val: æ¤œè¨¼ç‰¹å¾´é‡
        y_val: æ¤œè¨¼ãƒ©ãƒ™ãƒ«
        num_boost_round: ãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰æ•°
        early_stopping_rounds: æ—©æœŸåœæ­¢ãƒ©ã‚¦ãƒ³ãƒ‰æ•°
        seed: ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰
        verbose: è©³ç´°ãƒ­ã‚°ã‚’å‡ºåŠ›ã™ã‚‹ã‹
    
    Returns:
        ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ã®LightGBMãƒ¢ãƒ‡ãƒ«
    """
    if verbose:
        print("ğŸš€ LightGBMãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°é–‹å§‹")
    
    # LightGBMãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä½œæˆ
    train_data = lgb.Dataset(X_train, label=y_train)
    val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)
    
    # ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    params = {
        'objective': 'regression',
        'metric': 'mse',
        'boosting_type': 'gbdt',
        'num_leaves': 31,
        'learning_rate': 0.05,
        'feature_fraction': 0.9,
        'bagging_fraction': 0.8,
        'bagging_freq': 5,
        'verbose': -1 if not verbose else 0,
        'random_state': seed,
        'seed': seed,
        'bagging_seed': seed,
        'feature_fraction_seed': seed
    }
    
    # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
    callbacks = [
        lgb.early_stopping(stopping_rounds=early_stopping_rounds, verbose=verbose)
    ]
    if verbose:
        callbacks.append(lgb.log_evaluation(period=50))
    
    # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°
    bst = lgb.train(
        params,
        train_data,
        num_boost_round=num_boost_round,
        valid_sets=[train_data, val_data],
        valid_names=['train', 'valid'],
        callbacks=callbacks
    )
    
    return bst


def predict_flat_vector_model(bst: lgb.Booster, X: np.ndarray, lower_bound: float = 0.01) -> np.ndarray:
    """
    ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬
    
    Args:
        bst: LightGBMãƒ¢ãƒ‡ãƒ«
        X: ç‰¹å¾´é‡
        lower_bound: äºˆæ¸¬å€¤ã®ä¸‹é™
    
    Returns:
        äºˆæ¸¬å€¤ï¼ˆç§’å˜ä½ï¼‰
    """
    predictions = bst.predict(X, num_iteration=bst.best_iteration)
    
    # ä¸‹é™å€¤ã‚’é©ç”¨
    predictions = np.maximum(predictions, lower_bound)
    
    return predictions

