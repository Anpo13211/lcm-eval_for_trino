import collections

from cross_db_benchmark.benchmark_tools.trino.plan_operator import TrinoPlanOperator
import dgl
import numpy as np
import torch
from sklearn.preprocessing import RobustScaler

from cross_db_benchmark.benchmark_tools.trino.parse_filter import PredicateNode
from cross_db_benchmark.benchmark_tools.generate_workload import Operator
from training.featurizations import Featurization
from training.preprocessing.feature_statistics import FeatureType


def encode(column, plan_params, feature_statistics):
    """ç‰¹å¾´é‡ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã™ã‚‹"""
    # fallback in case actual cardinality is not in plan parameters
    if column == 'act_output_rows' and column not in plan_params:
        value = 0
    else:
        value = plan_params[column]
    
    if feature_statistics[column].get('type') == str(FeatureType.numeric):
        enc_value = feature_statistics[column]['scaler'].transform(np.array([[value]])).item()
    elif feature_statistics[column].get('type') == str(FeatureType.categorical):
        value_dict = feature_statistics[column]['value_dict']
        if isinstance(value, list) and len(value) == 1:
            value = value[0]
        
        # æœªçŸ¥ã®æ¼”ç®—å­åã«å¯¾ã—ã¦å‹•çš„ã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å‰²ã‚Šå½“ã¦
        if str(value) not in value_dict:
            # æ–°ã—ã„ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å‰²ã‚Šå½“ã¦ï¼ˆæ—¢å­˜ã®æœ€å¤§å€¤+1ï¼‰
            max_index = max(value_dict.values()) if value_dict else -1
            value_dict[str(value)] = max_index + 1
            print(f"âš ï¸  æœªçŸ¥ã®æ¼”ç®—å­å '{value}' ã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ {max_index + 1} ã‚’å‰²ã‚Šå½“ã¦ã¾ã—ãŸ")
        
        enc_value = value_dict[str(value)]
    else:
        raise NotImplementedError
    return enc_value


def plan_to_graph(node: TrinoPlanOperator, database_id, plan_depths, plan_features, plan_to_plan_edges, db_statistics, feature_statistics,
                  filter_to_plan_edges, predicate_col_features, output_column_to_plan_edges, output_column_features,
                  column_to_output_column_edges, column_features, table_features, table_to_plan_edges,
                  output_column_idx, column_idx, table_idx, plan_featurization: Featurization, predicate_depths, intra_predicate_edges,
                  logical_preds, parent_node_id=None, depth=0):
    """
    Trinoãƒ—ãƒ©ãƒ³ã‚’ã‚°ãƒ©ãƒ•ã«å¤‰æ›ã™ã‚‹
    
    å¼•æ•°ä¸€è¦§ï¼š
    1. å…¥åŠ›ãƒ‡ãƒ¼ã‚¿
        node: ç¾åœ¨å‡¦ç†ä¸­ã®Trinoå®Ÿè¡Œè¨ˆç”»ãƒãƒ¼ãƒ‰
        database_id: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®è­˜åˆ¥å­
        db_statistics: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®çµ±è¨ˆæƒ…å ±
        feature_statistics: ç‰¹å¾´é‡ã®çµ±è¨ˆæƒ…å ±
        plan_featurization: ç‰¹å¾´é‡åŒ–ã®è¨­å®š
    2. å‡ºåŠ›ç”¨ã®ãƒªã‚¹ãƒˆï¼ˆå‚ç…§æ¸¡ã—ã§æ›´æ–°ï¼‰
        plan_depths: å„ãƒ—ãƒ©ãƒ³ãƒãƒ¼ãƒ‰ã®æ·±åº¦
        plan_features: ãƒ—ãƒ©ãƒ³ãƒãƒ¼ãƒ‰ã®ç‰¹å¾´é‡
        plan_to_plan_edges: ãƒ—ãƒ©ãƒ³ãƒãƒ¼ãƒ‰é–“ã®ã‚¨ãƒƒã‚¸
        filter_to_plan_edges: ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‹ã‚‰ãƒ—ãƒ©ãƒ³ã¸ã®ã‚¨ãƒƒã‚¸
        predicate_col_features: è¿°èªã‚«ãƒ©ãƒ ã®ç‰¹å¾´é‡
        output_column_to_plan_edges: å‡ºåŠ›ã‚«ãƒ©ãƒ ã‹ã‚‰ãƒ—ãƒ©ãƒ³ã¸ã®ã‚¨ãƒƒã‚¸
        output_column_features: å‡ºåŠ›ã‚«ãƒ©ãƒ ã®ç‰¹å¾´é‡
        column_to_output_column_edges: ã‚«ãƒ©ãƒ ã‹ã‚‰å‡ºåŠ›ã‚«ãƒ©ãƒ ã¸ã®ã‚¨ãƒƒã‚¸
        column_features: ã‚«ãƒ©ãƒ ã®ç‰¹å¾´é‡
        table_features: ãƒ†ãƒ¼ãƒ–ãƒ«ã®ç‰¹å¾´é‡
        table_to_plan_edges: ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ãƒ—ãƒ©ãƒ³ã¸ã®ã‚¨ãƒƒã‚¸
        output_column_idx: å‡ºåŠ›ã‚«ãƒ©ãƒ ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        column_idx: ã‚«ãƒ©ãƒ ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        table_idx: ãƒ†ãƒ¼ãƒ–ãƒ«ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        plan_featurization: ãƒ—ãƒ©ãƒ³ã®ç‰¹å¾´é‡åŒ–è¨­å®š
        predicate_depths: è¿°èªã®æ·±åº¦
        intra_predicate_edges: è¿°èªå†…ã®ã‚¨ãƒƒã‚¸
        logical_preds: è«–ç†è¿°èª
        parent_node_id: è¦ªãƒãƒ¼ãƒ‰ã®ID
        depth: ç¾åœ¨ã®æ·±åº¦
    """
    
    # ç¾åœ¨ã®ãƒ—ãƒ©ãƒ³ãƒãƒ¼ãƒ‰ã®IDã‚’å–å¾—
    current_plan_id = len(plan_depths)
    plan_depths.append(depth)
    
    # ãƒ—ãƒ©ãƒ³ã®ç‰¹å¾´é‡ã‚’æŠ½å‡º
    plan_feat = []
    for feat_name in plan_featurization.VARIABLES['plan']:
        if feat_name in node.plan_parameters:
            # Trinoã®ç‰¹å¾´é‡åã‚’PostgreSQLäº’æ›ã«å¤‰æ›
            if feat_name == 'act_output_rows':
                # PostgreSQLã®act_cardã«å¯¾å¿œ
                value = node.plan_parameters[feat_name]
            elif feat_name == 'est_rows':
                # PostgreSQLã®est_cardã«å¯¾å¿œ
                value = node.plan_parameters[feat_name]
            else:
                value = node.plan_parameters[feat_name]
            
            enc_value = encode(feat_name, node.plan_parameters, feature_statistics)
            plan_feat.append(enc_value)
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            plan_feat.append(0.0)
    
    plan_features.append(plan_feat)
    
    # è¦ªå­é–¢ä¿‚ã®ã‚¨ãƒƒã‚¸ã‚’è¿½åŠ 
    if parent_node_id is not None:
        plan_to_plan_edges.append((current_plan_id, parent_node_id))
    
    # ãƒ†ãƒ¼ãƒ–ãƒ«æƒ…å ±ã®å‡¦ç†
    if 'table' in node.plan_parameters:
        table_name = node.plan_parameters['table']
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—ã¾ãŸã¯ä½œæˆ
        if table_name not in table_idx:
            table_idx[table_name] = len(table_features)
            
            # ãƒ†ãƒ¼ãƒ–ãƒ«ã®ç‰¹å¾´é‡ã‚’æŠ½å‡º
            table_feat = []
            for feat_name in plan_featurization.VARIABLES['table']:
                if feat_name in node.plan_parameters:
                    value = node.plan_parameters[feat_name]
                    enc_value = encode(feat_name, node.plan_parameters, feature_statistics)
                    table_feat.append(enc_value)
                else:
                    table_feat.append(0.0)
            
            table_features.append(table_feat)
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ãƒ—ãƒ©ãƒ³ã¸ã®ã‚¨ãƒƒã‚¸ã‚’è¿½åŠ 
        table_to_plan_edges.append((table_idx[table_name], current_plan_id))
    
    # ã‚«ãƒ©ãƒ æƒ…å ±ã®å‡¦ç†
    if 'columns' in node.plan_parameters:
        columns = node.plan_parameters['columns']
        for column in columns:
            # ã‚«ãƒ©ãƒ ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—ã¾ãŸã¯ä½œæˆ
            if column not in column_idx:
                column_idx[column] = len(column_features)
                
                # ã‚«ãƒ©ãƒ ã®ç‰¹å¾´é‡ã‚’æŠ½å‡ºï¼ˆTrinoã§ã¯0ã«è¨­å®šï¼‰
                column_feat = []
                for feat_name in plan_featurization.VARIABLES['column']:
                    column_feat.append(0.0)  # Trinoã§ã¯ã‚«ãƒ©ãƒ çµ±è¨ˆã‚’å–å¾—ã§ããªã„
                
                column_features.append(column_feat)
    
    # å‡ºåŠ›ã‚«ãƒ©ãƒ æƒ…å ±ã®å‡¦ç†
    if 'output_columns' in node.plan_parameters:
        output_columns = node.plan_parameters['output_columns']
        for output_col in output_columns:
            # å‡ºåŠ›ã‚«ãƒ©ãƒ ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—ã¾ãŸã¯ä½œæˆ
            if output_col not in output_column_idx:
                output_column_idx[output_col] = len(output_column_features)
                
                # å‡ºåŠ›ã‚«ãƒ©ãƒ ã®ç‰¹å¾´é‡ã‚’æŠ½å‡º
                output_col_feat = []
                for feat_name in plan_featurization.VARIABLES['output_column']:
                    output_col_feat.append(0.0)  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
                
                output_column_features.append(output_col_feat)
            
            # å‡ºåŠ›ã‚«ãƒ©ãƒ ã‹ã‚‰ãƒ—ãƒ©ãƒ³ã¸ã®ã‚¨ãƒƒã‚¸ã‚’è¿½åŠ 
            output_column_to_plan_edges.append((output_column_idx[output_col], current_plan_id))
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æƒ…å ±ã®å‡¦ç†
    if 'filter_predicate' in node.plan_parameters and node.plan_parameters['filter_predicate']:
        filter_predicate = node.plan_parameters['filter_predicate']
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®ç‰¹å¾´é‡ã‚’æŠ½å‡º
        filter_feat = []
        for feat_name in plan_featurization.VARIABLES['filter_column']:
            if feat_name == 'operator':
                # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¼”ç®—å­ã®ç‰¹å¾´é‡
                filter_feat.append(0.0)  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            elif feat_name == 'literal_feature':
                # ãƒªãƒ†ãƒ©ãƒ«å€¤ã®ç‰¹å¾´é‡
                filter_feat.append(0.0)  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            else:
                filter_feat.append(0.0)
        
        predicate_col_features.append(filter_feat)
        filter_to_plan_edges.append((len(predicate_col_features) - 1, current_plan_id))
    
    # å‹•çš„ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æƒ…å ±ã®å‡¦ç†
    if 'dynamic_filters' in node.plan_parameters and node.plan_parameters['dynamic_filters']:
        dynamic_filters = node.plan_parameters['dynamic_filters']
        
        # å‹•çš„ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®ç‰¹å¾´é‡ã‚’æŠ½å‡º
        dynamic_filter_feat = []
        for feat_name in plan_featurization.VARIABLES['filter_column']:
            dynamic_filter_feat.append(0.0)  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
        
        predicate_col_features.append(dynamic_filter_feat)
        filter_to_plan_edges.append((len(predicate_col_features) - 1, current_plan_id))
    
    # å­ãƒãƒ¼ãƒ‰ã‚’å†å¸°çš„ã«å‡¦ç†
    for child in node.children:
        plan_to_graph(child, database_id, plan_depths, plan_features, plan_to_plan_edges, db_statistics,
                      feature_statistics, filter_to_plan_edges, predicate_col_features, output_column_to_plan_edges,
                      output_column_features, column_to_output_column_edges, column_features, table_features,
                      table_to_plan_edges, output_column_idx, column_idx, table_idx,
                      plan_featurization, predicate_depths, intra_predicate_edges, logical_preds,
                      parent_node_id=current_plan_id, depth=depth + 1)


def trino_plan_collator(plans, feature_statistics: dict = None, db_statistics: dict = None,
                        plan_featurization: Featurization = None):
    """
    Trinoã®ç‰©ç†ãƒ—ãƒ©ãƒ³ã‚’å¤§ããªã‚°ãƒ©ãƒ•ã«çµåˆã—ã€MLãƒ¢ãƒ‡ãƒ«ã«æŠ•å…¥ã§ãã‚‹å½¢å¼ã«ã™ã‚‹
    
    Args:
        plans: Trinoãƒ—ãƒ©ãƒ³ã®ãƒªã‚¹ãƒˆ
        feature_statistics: ç‰¹å¾´é‡ã®çµ±è¨ˆæƒ…å ±
        db_statistics: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®çµ±è¨ˆæƒ…å ±
        plan_featurization: ãƒ—ãƒ©ãƒ³ã®ç‰¹å¾´é‡åŒ–è¨­å®š
    
    Returns:
        graph: DGLã®ç•°ç¨®ã‚°ãƒ©ãƒ•
        features: ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ã®è¾æ›¸
        labels: ãƒ©ãƒ™ãƒ«ï¼ˆå®Ÿè¡Œæ™‚é–“ï¼‰ã®ãƒªã‚¹ãƒˆ
        sample_idxs: ã‚µãƒ³ãƒ—ãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ãƒªã‚¹ãƒˆ
    """
    
    # å‡ºåŠ›ç”¨ã®ãƒªã‚¹ãƒˆ
    plan_depths = []
    plan_features = []
    plan_to_plan_edges = []
    filter_to_plan_edges = []
    filter_features = []
    output_column_to_plan_edges = []
    output_column_features = []
    column_to_output_column_edges = []
    column_features = []
    table_features = []
    table_to_plan_edges = []
    labels = []
    predicate_depths = []
    intra_predicate_edges = []
    logical_preds = []
    
    output_column_idx = dict()
    column_idx = dict()
    table_idx = dict()
    
    # æ•°å€¤ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ç”¨ã®ãƒ­ãƒã‚¹ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’æº–å‚™
    if feature_statistics is not None:
        add_numerical_scalers(feature_statistics)
    
    # ãƒ—ãƒ©ãƒ³ã‚’åå¾©å‡¦ç†ã—ã€ãƒãƒ¼ãƒ‰ã”ã¨ã®ã‚¨ãƒƒã‚¸ã¨ç‰¹å¾´é‡ã®ãƒªã‚¹ãƒˆã‚’ä½œæˆ
    sample_idxs = []
    for sample_idx, p in plans:
        sample_idxs.append(sample_idx)
        labels.append(p.plan_runtime)  # å„ã‚¯ã‚¨ãƒªã®å®Ÿè¡Œæ™‚é–“
        plan_to_graph(p, p.database_id, plan_depths, plan_features, plan_to_plan_edges, db_statistics,
                      feature_statistics, filter_to_plan_edges, filter_features, output_column_to_plan_edges,
                      output_column_features, column_to_output_column_edges, column_features, table_features,
                      table_to_plan_edges, output_column_idx, column_idx, table_idx,
                      plan_featurization, predicate_depths, intra_predicate_edges, logical_preds)
    
    assert len(labels) == len(plans)
    assert len(plan_depths) == len(plan_features)
    
    # æ·±åº¦ã«åŸºã¥ã„ã¦ãƒãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—ã‚’ä½œæˆ
    data_dict, nodes_per_depth, plan_dict = create_node_types_per_depth(plan_depths, plan_to_plan_edges)
    
    # è¿°èªãƒãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—ã‚’ä½œæˆ
    pred_dict = dict()
    nodes_per_pred_depth = collections.defaultdict(int)
    no_filter_columns = 0
    for pred_node, d in enumerate(predicate_depths):
        if logical_preds[pred_node]:
            pred_dict[pred_node] = (nodes_per_pred_depth[d], d)
            nodes_per_pred_depth[d] += 1
        else:
            pred_dict[pred_node] = no_filter_columns
            no_filter_columns += 1
    
    adapt_predicate_edges(data_dict, filter_to_plan_edges, intra_predicate_edges, logical_preds, plan_dict, pred_dict,
                          pred_node_type_id)
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã€ãƒ†ãƒ¼ãƒ–ãƒ«ã€ã‚«ãƒ©ãƒ ã€å‡ºåŠ›ã‚«ãƒ©ãƒ ã€ãƒ—ãƒ©ãƒ³ãƒãƒ¼ãƒ‰ã‚’ãƒãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—ã¨ã—ã¦è¿½åŠ 
    # ç©ºã§ãªã„ã‚¨ãƒƒã‚¸ã®ã¿ã‚’è¿½åŠ 
    if column_to_output_column_edges:
        data_dict[('column', 'col_output_col', 'output_column')] = column_to_output_column_edges
    
    for u, v in output_column_to_plan_edges:
        v_node_id, d_v = plan_dict[v]
        data_dict[('output_column', 'to_plan', f'plan{d_v}')].append((u, v_node_id))
    
    for u, v in table_to_plan_edges:
        v_node_id, d_v = plan_dict[v]
        data_dict[('table', 'to_plan', f'plan{d_v}')].append((u, v_node_id))
    
    # ãƒãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—ã”ã¨ã®ãƒãƒ¼ãƒ‰æ•°ã‚‚æ¸¡ã™
    max_depth, max_pred_depth = get_depths(plan_depths, predicate_depths)
    num_nodes_dict = {
        'column': len(column_features),
        'table': len(table_features),
        'output_column': len(output_column_features),
        'filter_column': max(1, len(logical_preds) - sum(logical_preds)),
    }
    num_nodes_dict = update_node_counts(max_depth, max_pred_depth, nodes_per_depth, nodes_per_pred_depth,
                                        num_nodes_dict)
    
    # ãƒ‡ãƒ¼ã‚¿è¾æ›¸ã«å­˜åœ¨ã™ã‚‹ãƒãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—ã®ã¿ã‚’num_nodes_dictã«å«ã‚ã‚‹
    used_node_types = set()
    for edge_type in data_dict.keys():
        used_node_types.add(edge_type[0])  # ã‚½ãƒ¼ã‚¹ãƒãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—
        used_node_types.add(edge_type[2])  # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—
    
    # ãƒãƒ¼ãƒ‰æ•°ãŒ0ã‚ˆã‚Šå¤§ãã„ãƒãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—ã‚‚å«ã‚ã‚‹
    for node_type, count in num_nodes_dict.items():
        if count > 0:
            used_node_types.add(node_type)
    
    # ä½¿ç”¨ã•ã‚Œã‚‹ãƒãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—ã®ã¿ã‚’num_nodes_dictã«å«ã‚ã‚‹ï¼ˆãƒãƒ¼ãƒ‰æ•°ãŒ0ã§ã‚‚å«ã‚ã‚‹ï¼‰
    filtered_num_nodes_dict = {k: v for k, v in num_nodes_dict.items() if k in used_node_types}
    
    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’å‡ºåŠ›
    print(f"ğŸ” num_nodes_dict: {num_nodes_dict}")
    print(f"ğŸ” used_node_types: {used_node_types}")
    print(f"ğŸ” filtered_num_nodes_dict: {filtered_num_nodes_dict}")
    
    # ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ
    graph = dgl.heterograph(data_dict, num_nodes_dict=filtered_num_nodes_dict)
    graph.max_depth = max_depth
    graph.max_pred_depth = max_pred_depth
    
    # ç‰¹å¾´é‡ã‚’æ•´ç†
    features = collections.defaultdict(list)
    
    # filter_columnã®ç‰¹å¾´é‡ã‚’ä½œæˆ
    filter_column_features = []
    if logical_preds:
        # logical_predsãŒå­˜åœ¨ã™ã‚‹å ´åˆ
        filter_column_features = [f for f, log_pred in zip(filter_features, logical_preds) if not log_pred]
    else:
        # logical_predsãŒç©ºã®å ´åˆã€filter_columnãƒãƒ¼ãƒ‰æ•°åˆ†ã®ãƒ€ãƒŸãƒ¼ç‰¹å¾´é‡ã‚’ä½œæˆ
        filter_column_count = max(1, len(logical_preds) - sum(logical_preds))
        if filter_column_count > 0:
            # ãƒ€ãƒŸãƒ¼ã®ç‰¹å¾´é‡ã‚’ä½œæˆï¼ˆã™ã¹ã¦0ï¼‰
            dummy_feature = [0.0] * len(plan_featurization.FILTER_FEATURES + plan_featurization.COLUMN_FEATURES)
            filter_column_features = [dummy_feature for _ in range(filter_column_count)]
    
    features.update(dict(column=column_features, table=table_features, output_column=output_column_features,
                         filter_column=filter_column_features))
    
    # æ·±åº¦ã«åŸºã¥ã„ã¦ãƒ—ãƒ©ãƒ³ç‰¹å¾´é‡ã‚’ã‚½ãƒ¼ãƒˆ
    for u, plan_feat in enumerate(plan_features):
        u_node_id, d_u = plan_dict[u]
        features[f'plan{d_u}'].append(plan_feat)
    
    # æ·±åº¦ã«åŸºã¥ã„ã¦è¿°èªç‰¹å¾´é‡ã‚’ã‚½ãƒ¼ãƒˆ
    for pred_node_id, pred_feat in enumerate(filter_features):
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒç¯„å›²å†…ã‹ãƒã‚§ãƒƒã‚¯
        if pred_node_id >= len(logical_preds):
            continue
        
        if not logical_preds[pred_node_id]:
            continue
        node_type, _ = pred_node_type_id(logical_preds, pred_dict, pred_node_id)
        features[node_type].append(pred_feat)
    
    features = postprocess_feats(features, filtered_num_nodes_dict)
    
    # å®Ÿè¡Œæ™‚é–“ã‚’ç§’å˜ä½ã§å‡¦ç†
    labels = postprocess_labels(labels)
    
    return graph, features, labels, sample_idxs


def postprocess_labels(labels):
    """ãƒ©ãƒ™ãƒ«ã‚’å¾Œå‡¦ç†ã™ã‚‹"""
    labels = np.array(labels, dtype=np.float32)
    labels /= 1000  # ãƒŸãƒªç§’ã‹ã‚‰ç§’ã«å¤‰æ›
    return labels


def postprocess_feats(features, num_nodes_dict):
    """ç‰¹å¾´é‡ã‚’å¾Œå‡¦ç†ã™ã‚‹"""
    # ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›ã—ã€nanã‚’0ã«ç½®æ›
    for k in features.keys():
        v = features[k]
        v = np.array(v, dtype=np.float32)
        v = np.nan_to_num(v, nan=0.0)
        v = torch.from_numpy(v)
        features[k] = v
    # ãƒãƒ¼ãƒ‰æ•°ãŒ0ã®ãƒãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    features = {k: v for k, v in features.items() if k in num_nodes_dict}
    return features


def update_node_counts(max_depth, max_pred_depth, nodes_per_depth, nodes_per_pred_depth, num_nodes_dict):
    """ãƒãƒ¼ãƒ‰æ•°ã‚’æ›´æ–°ã™ã‚‹"""
    for d in range(max_depth + 1):
        num_nodes_dict[f'plan{d}'] = nodes_per_depth[d]
    for d in range(max_pred_depth + 1):
        num_nodes_dict[f'logical_pred_{d}'] = nodes_per_pred_depth[d]
    # ãƒãƒ¼ãƒ‰æ•°ãŒ0ã®ãƒãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    num_nodes_dict = {k: v for k, v in num_nodes_dict.items() if v > 0}
    return num_nodes_dict


def get_depths(plan_depths, predicate_depths):
    """æ·±åº¦ã‚’å–å¾—ã™ã‚‹"""
    max_depth = max(plan_depths)
    max_pred_depth = 0
    if len(predicate_depths) > 0:
        max_pred_depth = max(predicate_depths)
    return max_depth, max_pred_depth


def adapt_predicate_edges(data_dict, filter_to_plan_edges, intra_predicate_edges, logical_preds, plan_dict, pred_dict,
                          pred_node_type_id_func):
    """è¿°èªã‚¨ãƒƒã‚¸ã‚’é©å¿œã™ã‚‹"""
    # ãƒ—ãƒ©ãƒ³ã‚¨ãƒƒã‚¸ã«å¤‰æ›
    for u, v in filter_to_plan_edges:
        # ãƒ—ãƒ©ãƒ³ãƒãƒ¼ãƒ‰ã‚’æ­£ã—ã„IDã¨æ·±åº¦ã«å¤‰æ›
        v_node_id, d_v = plan_dict[v]
        # è¿°èªãƒãƒ¼ãƒ‰ã‚’æ­£ã—ã„ãƒãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—ã¨IDã«å¤‰æ›
        node_type, u_node_id = pred_node_type_id_func(logical_preds, pred_dict, u)
        
        data_dict[(node_type, 'to_plan', f'plan{d_v}')].append((u_node_id, v_node_id))
    
    # è¿°èªå†…ã‚¨ãƒƒã‚¸ã‚’å¤‰æ›ï¼ˆä¾‹ï¼šã‚«ãƒ©ãƒ ã‹ã‚‰ANDã¸ï¼‰
    for u, v in intra_predicate_edges:
        u_node_type, u_node_id = pred_node_type_id_func(logical_preds, pred_dict, u)
        v_node_type, v_node_id = pred_node_type_id_func(logical_preds, pred_dict, v)
        data_dict[(u_node_type, 'intra_predicate', v_node_type)].append((u_node_id, v_node_id))


def create_node_types_per_depth(plan_depths, plan_to_plan_edges):
    """æ·±åº¦ã”ã¨ã«ãƒãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—ã‚’ä½œæˆã™ã‚‹"""
    # ç•°ç¨®ã‚°ãƒ©ãƒ•ã‚’ä½œæˆï¼šãƒãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—: table, column, filter_column, logical_pred, output_column, plan{depth}
    # ã¾ãšã€å¤ã„ãƒ—ãƒ©ãƒ³ãƒãƒ¼ãƒ‰ID -> æ·±åº¦ã¨ãƒãƒ¼ãƒ‰IDã®ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½œæˆ
    plan_dict = dict()
    nodes_per_depth = collections.defaultdict(int)
    for plan_node, d in enumerate(plan_depths):
        plan_dict[plan_node] = (nodes_per_depth[d], d)
        nodes_per_depth[d] += 1
    
    # ãƒ—ãƒ©ãƒ³ã®æ·±åº¦ã«å¿œã˜ã¦ã‚¨ãƒƒã‚¸ã¨ãƒãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—ã‚’ä½œæˆ
    data_dict = collections.defaultdict(list)
    for u, v in plan_to_plan_edges:
        u_node_id, d_u = plan_dict[u]
        v_node_id, d_v = plan_dict[v]
        assert d_v < d_u
        data_dict[(f'plan{d_u}', f'intra_plan', f'plan{d_v}')].append((u_node_id, v_node_id))
    
    return data_dict, nodes_per_depth, plan_dict


def add_numerical_scalers(feature_statistics):
    """æ•°å€¤ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã‚’è¿½åŠ ã™ã‚‹"""
    for k, v in feature_statistics.items():
        if v.get('type') == str(FeatureType.numeric):
            scaler = RobustScaler()
            scaler.center_ = v['center']
            scaler.scale_ = v['scale']
            feature_statistics[k]['scaler'] = scaler


def pred_node_type_id(logical_preds, pred_dict, u):
    """è¿°èªãƒãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—IDã‚’å–å¾—ã™ã‚‹"""
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒç¯„å›²å†…ã‹ãƒã‚§ãƒƒã‚¯
    if u >= len(logical_preds):
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨ï¼ˆè­¦å‘Šã¯è¡¨ç¤ºã—ãªã„ï¼‰
        u_node_id = pred_dict.get(u, 0)
        node_type = f'filter_column'
        return node_type, u_node_id
    
    if logical_preds[u]:
        u_node_id, depth = pred_dict[u]
        node_type = f'logical_pred_{depth}'
    else:
        u_node_id = pred_dict[u]
        node_type = f'filter_column'
    return node_type, u_node_id