"""
Trino Zero-Shotãƒ¢ãƒ‡ãƒ«ã®ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ†ã‚¹ãƒˆ
"""
import sys
import os
from pathlib import Path

# ç’°å¢ƒå¤‰æ•°ã®è¨­å®šï¼ˆå¿…é ˆ - importå‰ã«å®Ÿè¡Œï¼‰
for i in range(11):
    env_key = f'NODE{i:02d}'
    if os.environ.get(env_key) in (None, '', 'None'):
        os.environ[env_key] = '[]'

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent / 'src'))

import torch
import numpy as np
from pathlib import Path
from types import SimpleNamespace

def test_end_to_end():
    """ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ†ã‚¹ãƒˆ"""
    
    print("=" * 80)
    print("Trino Zero-Shotãƒ¢ãƒ‡ãƒ« ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ†ã‚¹ãƒˆ")
    print("=" * 80)
    
    # 1. ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
    test_file = Path("/Users/an/query_engine/explain_analyze_results/accidents_combined_workloads_explain_analyze.txt")
    if not test_file.exists():
        print(f"âŒ ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {test_file}")
        return False
    
    print(f"\nâœ… ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«: {test_file}")
    
    # 2. ãƒ—ãƒ©ãƒ³ã®èª­ã¿è¾¼ã¿
    print("\nğŸ“‚ ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ—ãƒ©ãƒ³ã®èª­ã¿è¾¼ã¿")
    try:
        from training.dataset.dataset_creation import read_explain_analyze_txt
        
        plans, database_stats = read_explain_analyze_txt(
            test_file,
            path_index=0,
            limit_per_ds=5  # 5ãƒ—ãƒ©ãƒ³ã§ãƒ†ã‚¹ãƒˆ
        )
        
        print(f"âœ… {len(plans)} ãƒ—ãƒ©ãƒ³ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
        print(f"   - database_stats.table_stats: {len(database_stats.table_stats)} ãƒ†ãƒ¼ãƒ–ãƒ«")
        print(f"   - database_stats.column_stats: {len(database_stats.column_stats)} ã‚«ãƒ©ãƒ ")
        
        if len(plans) == 0:
            print("âŒ ãƒ—ãƒ©ãƒ³ãŒ0å€‹ã§ã™")
            return False
            
    except Exception as e:
        print(f"âŒ ãƒ—ãƒ©ãƒ³èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # 3. çµ±è¨ˆæƒ…å ±ã®æº–å‚™
    print("\nğŸ“Š ã‚¹ãƒ†ãƒƒãƒ—2: çµ±è¨ˆæƒ…å ±ã®æº–å‚™")
    try:
        # db_statisticsã‚’Postgreså½¢å¼ã§æº–å‚™
        db_statistics = {
            0: database_stats
        }
        print(f"âœ… db_statisticsæº–å‚™å®Œäº†")
        print(f"   - table_stats: {len(db_statistics[0].table_stats)} ãƒ†ãƒ¼ãƒ–ãƒ«")
        print(f"   - column_stats: {len(db_statistics[0].column_stats)} ã‚«ãƒ©ãƒ ")
    except Exception as e:
        print(f"âŒ çµ±è¨ˆæƒ…å ±æº–å‚™ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # 4. ç‰¹å¾´é‡çµ±è¨ˆã®æº–å‚™
    print("\nğŸ”§ ã‚¹ãƒ†ãƒƒãƒ—3: ç‰¹å¾´é‡çµ±è¨ˆã®æº–å‚™")
    try:
        from training.featurizations import TrinoTrueCardDetail
        from sklearn.preprocessing import RobustScaler
        from training.preprocessing.feature_statistics import FeatureType
        import numpy as np
        
        plan_featurization = TrinoTrueCardDetail()
        
        # å¿…è¦ãªç‰¹å¾´é‡ã‚’ã™ã¹ã¦å«ã‚€feature_statisticsã‚’ä½œæˆ
        feature_statistics = {}
        
        # PLAN_FEATURES
        for feat in plan_featurization.PLAN_FEATURES:
            if feat == 'op_name':
                feature_statistics[feat] = {
                    'type': str(FeatureType.categorical),
                    'value_dict': {'ScanFilterProject': 0, 'FilterProject': 1, 'Output': 2, 'Aggregate': 3},
                    'no_vals': 100
                }
            else:
                feature_statistics[feat] = {
                    'type': str(FeatureType.numeric),
                    'center': 1000.0,
                    'scale': 500.0,
                }
        
        # FILTER_FEATURES
        for feat in plan_featurization.FILTER_FEATURES:
            if feat == 'operator':
                feature_statistics[feat] = {
                    'type': str(FeatureType.categorical),
                    'value_dict': {'=': 0, '$eq': 1, '$gt': 2, '$lt': 3},
                    'no_vals': 50
                }
            else:
                feature_statistics[feat] = {
                    'type': str(FeatureType.numeric),
                    'center': 0.0,
                    'scale': 1.0,
                }
        
        # COLUMN_FEATURES
        for feat in plan_featurization.COLUMN_FEATURES:
            feature_statistics[feat] = {
                'type': str(FeatureType.numeric),
                'center': 0.0,
                'scale': 1.0,
            }
        
        # TABLE_FEATURES
        for feat in plan_featurization.TABLE_FEATURES:
            feature_statistics[feat] = {
                'type': str(FeatureType.numeric),
                'center': 10000.0,
                'scale': 5000.0,
            }
        
        # OUTPUT_COLUMN_FEATURES
        for feat in plan_featurization.OUTPUT_COLUMN_FEATURES:
            if feat == 'aggregation':
                feature_statistics[feat] = {
                    'type': str(FeatureType.categorical),
                    'value_dict': {'Aggregator.COUNT': 0, 'Aggregator.SUM': 1, None: 2},
                    'no_vals': 10
                }
            else:
                feature_statistics[feat] = {
                    'type': str(FeatureType.numeric),
                    'center': 0.0,
                    'scale': 1.0,
                }
        
        # RobustScalerã‚’è¿½åŠ 
        for k, v in feature_statistics.items():
            if v.get('type') == str(FeatureType.numeric):
                scaler = RobustScaler()
                scaler.center_ = np.array([v['center']])
                scaler.scale_ = np.array([v['scale']])
                feature_statistics[k]['scaler'] = scaler
        
        print(f"âœ… feature_statisticsæº–å‚™å®Œäº†: {len(feature_statistics)} ç‰¹å¾´é‡")
        
    except Exception as e:
        print(f"âŒ ç‰¹å¾´é‡çµ±è¨ˆæº–å‚™ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # 5. trino_plan_collatorã®ãƒ†ã‚¹ãƒˆ
    print("\nğŸ“¦ ã‚¹ãƒ†ãƒƒãƒ—4: trino_plan_collatorã®ãƒ†ã‚¹ãƒˆ")
    try:
        from models.zeroshot.trino_plan_batching import trino_plan_collator
        
        # plansã‚’(sample_idx, plan)ã®ã‚¿ãƒ—ãƒ«ãƒªã‚¹ãƒˆã«å¤‰æ›
        plans_with_idx = [(i, plan) for i, plan in enumerate(plans)]
        
        graph, features, labels, sample_idxs = trino_plan_collator(
            plans=plans_with_idx,
            feature_statistics=feature_statistics,
            db_statistics=db_statistics,
            plan_featurization=plan_featurization
        )
        
        print(f"âœ… trino_plan_collatoræˆåŠŸ")
        print(f"   - graph: {graph}")
        print(f"   - features keys: {list(features.keys())}")
        print(f"   - labels: {labels.shape if hasattr(labels, 'shape') else len(labels)}")
        print(f"   - sample_idxs: {sample_idxs}")
        
        # ç‰¹å¾´é‡ã®ç¢ºèª
        for feat_name, feat_tensor in features.items():
            if hasattr(feat_tensor, 'shape'):
                print(f"   - {feat_name}: shape={feat_tensor.shape}")
            else:
                print(f"   - {feat_name}: len={len(feat_tensor)}")
        
    except Exception as e:
        print(f"âŒ trino_plan_collatorã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # 6. ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã¨ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹ãƒ†ã‚¹ãƒˆ
    print("\nğŸ¤– ã‚¹ãƒ†ãƒƒãƒ—5: ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã¨ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹")
    try:
        from models.zeroshot.specific_models.trino_zero_shot import TrinoZeroShotModel
        from classes.classes import ZeroShotModelConfig
        
        model_config = ZeroShotModelConfig(
            hidden_dim=64,  # ãƒ†ã‚¹ãƒˆç”¨ã«å°ã•ã‚
            hidden_dim_plan=64,
            hidden_dim_pred=64,
            p_dropout=0.1,
            featurization=plan_featurization,
            output_dim=1,
            batch_size=2
        )
        
        encoders = [
            ('plan', plan_featurization.PLAN_FEATURES),
            ('logical_pred', plan_featurization.FILTER_FEATURES),
            ('column', plan_featurization.COLUMN_FEATURES),
            ('table', plan_featurization.TABLE_FEATURES),
            ('filter_column', plan_featurization.FILTER_FEATURES + plan_featurization.COLUMN_FEATURES),
            ('output_column', plan_featurization.OUTPUT_COLUMN_FEATURES)
        ]
        
        # prepassesã¯ã€ã‚°ãƒ©ãƒ•ã«ã‚¨ãƒƒã‚¸ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿è¨­å®š
        # column_to_output_column_edgesãŒç©ºã®å ´åˆã¯prepassesã‚’ç©ºã«ã™ã‚‹
        prepasses = []  # ãƒ†ã‚¹ãƒˆç”¨ã«ç©ºã«ã™ã‚‹ï¼ˆcol_output_colã‚¨ãƒƒã‚¸ãŒãªã„å ´åˆãŒã‚ã‚‹ãŸã‚ï¼‰
        tree_model_types = []  # prepassesãŒç©ºã®å ´åˆã¯tree_model_typesã‚‚ç©ºã«ã™ã‚‹
        
        model = TrinoZeroShotModel(
            model_config=model_config,
            device='cpu',
            feature_statistics=feature_statistics,
            plan_featurization=plan_featurization,
            prepasses=prepasses,
            add_tree_model_types=tree_model_types,
            encoders=encoders
        )
        
        print(f"âœ… ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–æˆåŠŸ")
        print(f"   - ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in model.parameters()):,}")
        
        # ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹ãƒ†ã‚¹ãƒˆ
        model.eval()
        with torch.no_grad():
            predictions = model((graph, features))
            print(f"âœ… ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹æˆåŠŸ")
            print(f"   - predictions shape: {predictions.shape}")
            print(f"   - predictions sample: {predictions[:3].flatten().tolist()}")
        
    except Exception as e:
        print(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # 7. train_zeroshot.pyã®ä¸»è¦æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ
    print("\nğŸ” ã‚¹ãƒ†ãƒƒãƒ—6: train_zeroshot.pyã®ä¸»è¦æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ")
    try:
        # train_zeroshot.pyã®é–¢æ•°ã‚’ãƒ†ã‚¹ãƒˆ
        from trino_lcm.scripts.train_zeroshot import (
            load_plans_from_files,
            create_dummy_feature_statistics,
            TrinoPlanDataset
        )
        
        # ãƒ—ãƒ©ãƒ³ã®èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ
        test_files = [test_file]
        loaded_plans = load_plans_from_files(test_files, max_plans_per_file=3)
        print(f"âœ… load_plans_from_filesæˆåŠŸ: {len(loaded_plans)} ãƒ—ãƒ©ãƒ³")
        
        # ç‰¹å¾´é‡çµ±è¨ˆã®ä½œæˆãƒ†ã‚¹ãƒˆ
        dummy_stats = create_dummy_feature_statistics(plan_featurization)
        print(f"âœ… create_dummy_feature_statisticsæˆåŠŸ: {len(dummy_stats)} ç‰¹å¾´é‡")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä½œæˆãƒ†ã‚¹ãƒˆ
        dataset = TrinoPlanDataset(plans[:3])
        print(f"âœ… TrinoPlanDatasetä½œæˆæˆåŠŸ: {len(dataset)} ã‚µãƒ³ãƒ—ãƒ«")
        
    except Exception as e:
        print(f"âŒ train_zeroshot.pyæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    print("\n" + "=" * 80)
    print("âœ… ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ†ã‚¹ãƒˆæˆåŠŸ")
    print("=" * 80)
    return True


if __name__ == "__main__":
    success = test_end_to_end()
    if not success:
        sys.exit(1)

